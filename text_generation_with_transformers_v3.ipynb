{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdb5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor, string\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, Layer\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def func(txt):\n",
    "    txt=txt.split(',')\n",
    "    return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17abb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(text,  window):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        try:\n",
    "            \n",
    "            sequence = text[i:i+window]\n",
    "\n",
    "            target = text[i+1:i+1+window]\n",
    "\n",
    "            x.append(sequence)\n",
    "            y.append(target)\n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df86424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16129446",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ffbd9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# topics=pd.read_excel('16dom_.xlsx')[['Dominant_topic','Topic_Keywords']].groupby('Dominant_topic').agg({'Topic_Keywords':'first'}).reset_index()\n",
    "# topics = topics['Topic_Keywords'].tolist()\n",
    "# topics_list = []\n",
    "# for i in topics:\n",
    "#     topics_list.append(tf.convert_to_tensor((i.split(','))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572f05db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>Dominant_topic</th>\n",
       "      <th>Topic_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.463667</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>linguistic input features improve neural machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574052</td>\n",
       "      <td>system,model,language,evaluation,score,example...</td>\n",
       "      <td>multiresolution recurrent neural networks appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.391236</td>\n",
       "      <td>visual,feature,image,network,video,object,mult...</td>\n",
       "      <td>captions visual concepts back hao fang saurabh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567423</td>\n",
       "      <td>user,item,recommendation,model,matrix,system,m...</td>\n",
       "      <td>deep reinforcement learning recommendations xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.369361</td>\n",
       "      <td>word,model,text,classiﬁcation,document,sentime...</td>\n",
       "      <td>sentiment classiﬁcation document embeddings tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>3</td>\n",
       "      <td>0.618639</td>\n",
       "      <td>user,item,recommendation,model,matrix,system,m...</td>\n",
       "      <td>journal tex class files vol august deepfm wide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>13</td>\n",
       "      <td>0.471496</td>\n",
       "      <td>word,model,text,classiﬁcation,document,sentime...</td>\n",
       "      <td>funnelling new ensemble method heterogeneous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>13</td>\n",
       "      <td>0.650212</td>\n",
       "      <td>word,model,text,classiﬁcation,document,sentime...</td>\n",
       "      <td>published conference paper iclr limmable eural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349310</td>\n",
       "      <td>system,model,language,evaluation,score,example...</td>\n",
       "      <td>effective word order text categorization convo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1051</td>\n",
       "      <td>3</td>\n",
       "      <td>0.922728</td>\n",
       "      <td>user,item,recommendation,model,matrix,system,m...</td>\n",
       "      <td>multimodality help machine translation caption...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document  Dominant_topic  Topic_Contribution  \\\n",
       "0            0              12            0.463667   \n",
       "1            1               0            0.574052   \n",
       "2            2               7            0.391236   \n",
       "3            3               3            0.567423   \n",
       "4            4              13            0.369361   \n",
       "...        ...             ...                 ...   \n",
       "1047      1047               3            0.618639   \n",
       "1048      1048              13            0.471496   \n",
       "1049      1049              13            0.650212   \n",
       "1050      1050               0            0.349310   \n",
       "1051      1051               3            0.922728   \n",
       "\n",
       "                                         Topic_Keywords  \\\n",
       "0     translation,language,machine,system,source,mod...   \n",
       "1     system,model,language,evaluation,score,example...   \n",
       "2     visual,feature,image,network,video,object,mult...   \n",
       "3     user,item,recommendation,model,matrix,system,m...   \n",
       "4     word,model,text,classiﬁcation,document,sentime...   \n",
       "...                                                 ...   \n",
       "1047  user,item,recommendation,model,matrix,system,m...   \n",
       "1048  word,model,text,classiﬁcation,document,sentime...   \n",
       "1049  word,model,text,classiﬁcation,document,sentime...   \n",
       "1050  system,model,language,evaluation,score,example...   \n",
       "1051  user,item,recommendation,model,matrix,system,m...   \n",
       "\n",
       "                                                   text  \n",
       "0     linguistic input features improve neural machi...  \n",
       "1     multiresolution recurrent neural networks appl...  \n",
       "2     captions visual concepts back hao fang saurabh...  \n",
       "3     deep reinforcement learning recommendations xi...  \n",
       "4     sentiment classiﬁcation document embeddings tr...  \n",
       "...                                                 ...  \n",
       "1047  journal tex class files vol august deepfm wide...  \n",
       "1048   funnelling new ensemble method heterogeneous ...  \n",
       "1049  published conference paper iclr limmable eural...  \n",
       "1050  effective word order text categorization convo...  \n",
       "1051  multimodality help machine translation caption...  \n",
       "\n",
       "[1052 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=pd.read_excel('16dom.xlsx')\n",
    "\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87eee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_contribution={}\n",
    "topics_df = pd.DataFrame()\n",
    "for t in topics['Dominant_topic'].unique():\n",
    "    mean_c=topics[topics['Dominant_topic']==t]['Topic_Contribution'].mean()\n",
    "    topics[topics['Topic_Contribution']>mean_c]\n",
    "    topic_contribution[t]=mean_c\n",
    "    \n",
    "    topics_df = topics_df.append(topics[(topics['Dominant_topic']==t)&(topics['Topic_Contribution']>mean_c)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6056f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    88\n",
       "14    86\n",
       "0     75\n",
       "3     42\n",
       "9     34\n",
       "12    31\n",
       "5     30\n",
       "15    28\n",
       "11    21\n",
       "7     19\n",
       "10    16\n",
       "1     10\n",
       "8      6\n",
       "2      2\n",
       "4      2\n",
       "Name: Dominant_topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df\n",
    "topics_df['Dominant_topic'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38759e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_theme()\n",
    "# plt.plot(topics['Topic_Contribution'])\n",
    "# plt.title('Topic Contribution')\n",
    "# plt.ylabel('contribution')\n",
    "# # plt.legend(['Train loss', 'Valid loss'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09307ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a858b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>topic</th>\n",
       "      <th>Topic_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.463667</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>linguistic input features improve neural machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0.555811</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>punch positive unlabelled classification retri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>0.492599</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>language models unsupervised multitask learner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>12</td>\n",
       "      <td>0.619250</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>neural network language modeling features impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>0.622059</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>towards recommender dialog system qibin chen j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc  topic  Topic_Contribution  \\\n",
       "0      0     12            0.463667   \n",
       "14    14     12            0.555811   \n",
       "42    42     12            0.492599   \n",
       "99    99     12            0.619250   \n",
       "134  134     12            0.622059   \n",
       "\n",
       "                                        Topic_Keywords  \\\n",
       "0    translation,language,machine,system,source,mod...   \n",
       "14   translation,language,machine,system,source,mod...   \n",
       "42   translation,language,machine,system,source,mod...   \n",
       "99   translation,language,machine,system,source,mod...   \n",
       "134  translation,language,machine,system,source,mod...   \n",
       "\n",
       "                                                  text  \n",
       "0    linguistic input features improve neural machi...  \n",
       "14   punch positive unlabelled classification retri...  \n",
       "42   language models unsupervised multitask learner...  \n",
       "99   neural network language modeling features impo...  \n",
       "134  towards recommender dialog system qibin chen j...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    '''a function which convert a given text into tokens'''\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "# df = pd.read_excel('train.xlsx')\n",
    "df = topics_df.copy()\n",
    "df.columns = ['doc', 'topic', 'Topic_Contribution', 'Topic_Keywords', 'text']\n",
    "df=df.dropna()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e703cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    88\n",
       "14    86\n",
       "0     73\n",
       "3     42\n",
       "9     34\n",
       "12    31\n",
       "5     28\n",
       "15    28\n",
       "11    21\n",
       "7     19\n",
       "10    16\n",
       "1     10\n",
       "8      6\n",
       "2      2\n",
       "4      2\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a0b67",
   "metadata": {},
   "source": [
    "# Build sequence to sequence dataset\n",
    "* x = seq[0:i]\n",
    "* y = seq[1:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbdf796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 40, 51, 52, 57, 95, 126, 139, 144, 167, 18...</td>\n",
       "      <td>multiresolution recurrent neural networks appl...</td>\n",
       "      <td>system,model,language,evaluation,score,example...</td>\n",
       "      <td>[multiresolution, recurrent, neural, networks,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[80, 209, 227, 407, 437, 450, 492, 889, 1035, ...</td>\n",
       "      <td>adaptive learning sentiment classiﬁcation ruid...</td>\n",
       "      <td>model,feature,deep,data,learning,network,layer...</td>\n",
       "      <td>[adaptive, learning, sentiment, classiﬁcation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[50, 550]</td>\n",
       "      <td>e uniﬁed toolkit text retrieval analysis sean ...</td>\n",
       "      <td>latent,variational,vae,inference,log,variable,...</td>\n",
       "      <td>[e, uniﬁed, toolkit, text, retrieval, analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3, 7, 25, 29, 38, 49, 75, 85, 142, 148, 237, ...</td>\n",
       "      <td>deep reinforcement learning recommendations xi...</td>\n",
       "      <td>user,item,recommendation,model,matrix,system,m...</td>\n",
       "      <td>[deep, reinforcement, learning, recommendation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[704, 725]</td>\n",
       "      <td>language model pretraining guillaume lample fa...</td>\n",
       "      <td>entity,relation,knowledge,graph,embeddings,tri...</td>\n",
       "      <td>[language, model, pretraining, guillaume, lamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[24, 55, 68, 83, 88, 183, 218, 232, 249, 265, ...</td>\n",
       "      <td>convolutional neural network language models p...</td>\n",
       "      <td>word,model,embeddings,vector,language,sentence...</td>\n",
       "      <td>[convolutional, neural, network, language, mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[62, 74, 78, 174, 238, 248, 290, 394, 609, 662...</td>\n",
       "      <td>parsing language modeling kook choe brown univ...</td>\n",
       "      <td>visual,feature,image,network,video,object,mult...</td>\n",
       "      <td>[parsing, language, modeling, kook, choe, brow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[67, 200, 442, 519, 565, 832]</td>\n",
       "      <td>learning sentence representations via model mu...</td>\n",
       "      <td>graph,node,tree,edge,structure,walk,parsing,fe...</td>\n",
       "      <td>[learning, sentence, representations, via, mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[27, 30, 32, 39, 60, 76, 90, 118, 125, 234, 32...</td>\n",
       "      <td>memory networks personalised recommendation xi...</td>\n",
       "      <td>algorithm,learning,method,data,training,ˆ,valu...</td>\n",
       "      <td>[memory, networks, personalised, recommendatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[66, 94, 159, 236, 325, 372, 418, 435, 451, 68...</td>\n",
       "      <td>published conference paper iclr raternal ropou...</td>\n",
       "      <td>speech,language,recognition,model,word,system,...</td>\n",
       "      <td>[published, conference, paper, iclr, raternal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[161, 201, 219, 224, 244, 268, 278, 338, 468, ...</td>\n",
       "      <td>estimating attention flow online video network...</td>\n",
       "      <td>model,question,language,bert,task,answer,token...</td>\n",
       "      <td>[estimating, attention, flow, online, video, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[0, 14, 42, 99, 134, 170, 187, 262, 273, 276, ...</td>\n",
       "      <td>linguistic input features improve neural machi...</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>[linguistic, input, features, improve, neural,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[5, 31, 56, 70, 77, 86, 89, 92, 102, 103, 127,...</td>\n",
       "      <td>fusing document collection label representatio...</td>\n",
       "      <td>word,model,text,classiﬁcation,document,sentime...</td>\n",
       "      <td>[fusing, document, collection, label, represen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[15, 17, 22, 44, 63, 79, 106, 111, 120, 129, 1...</td>\n",
       "      <td>online learning eﬀort reduction interactive ne...</td>\n",
       "      <td>model,network,layer,neural,training,learning,i...</td>\n",
       "      <td>[online, learning, eﬀort, reduction, interacti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[18, 132, 152, 212, 272, 292, 385, 386, 441, 5...</td>\n",
       "      <td>relational recurrent neural networks adam sant...</td>\n",
       "      <td>model,sentence,sequence,generation,word,attent...</td>\n",
       "      <td>[relational, recurrent, neural, networks, adam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                                doc  \\\n",
       "0       0  [1, 40, 51, 52, 57, 95, 126, 139, 144, 167, 18...   \n",
       "1       1  [80, 209, 227, 407, 437, 450, 492, 889, 1035, ...   \n",
       "2       2                                          [50, 550]   \n",
       "3       3  [3, 7, 25, 29, 38, 49, 75, 85, 142, 148, 237, ...   \n",
       "4       4                                         [704, 725]   \n",
       "5       5  [24, 55, 68, 83, 88, 183, 218, 232, 249, 265, ...   \n",
       "6       7  [62, 74, 78, 174, 238, 248, 290, 394, 609, 662...   \n",
       "7       8                      [67, 200, 442, 519, 565, 832]   \n",
       "8       9  [27, 30, 32, 39, 60, 76, 90, 118, 125, 234, 32...   \n",
       "9      10  [66, 94, 159, 236, 325, 372, 418, 435, 451, 68...   \n",
       "10     11  [161, 201, 219, 224, 244, 268, 278, 338, 468, ...   \n",
       "11     12  [0, 14, 42, 99, 134, 170, 187, 262, 273, 276, ...   \n",
       "12     13  [5, 31, 56, 70, 77, 86, 89, 92, 102, 103, 127,...   \n",
       "13     14  [15, 17, 22, 44, 63, 79, 106, 111, 120, 129, 1...   \n",
       "14     15  [18, 132, 152, 212, 272, 292, 385, 386, 441, 5...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   multiresolution recurrent neural networks appl...   \n",
       "1   adaptive learning sentiment classiﬁcation ruid...   \n",
       "2   e uniﬁed toolkit text retrieval analysis sean ...   \n",
       "3   deep reinforcement learning recommendations xi...   \n",
       "4   language model pretraining guillaume lample fa...   \n",
       "5   convolutional neural network language models p...   \n",
       "6   parsing language modeling kook choe brown univ...   \n",
       "7   learning sentence representations via model mu...   \n",
       "8   memory networks personalised recommendation xi...   \n",
       "9   published conference paper iclr raternal ropou...   \n",
       "10  estimating attention flow online video network...   \n",
       "11  linguistic input features improve neural machi...   \n",
       "12  fusing document collection label representatio...   \n",
       "13  online learning eﬀort reduction interactive ne...   \n",
       "14  relational recurrent neural networks adam sant...   \n",
       "\n",
       "                                       Topic_Keywords  \\\n",
       "0   system,model,language,evaluation,score,example...   \n",
       "1   model,feature,deep,data,learning,network,layer...   \n",
       "2   latent,variational,vae,inference,log,variable,...   \n",
       "3   user,item,recommendation,model,matrix,system,m...   \n",
       "4   entity,relation,knowledge,graph,embeddings,tri...   \n",
       "5   word,model,embeddings,vector,language,sentence...   \n",
       "6   visual,feature,image,network,video,object,mult...   \n",
       "7   graph,node,tree,edge,structure,walk,parsing,fe...   \n",
       "8   algorithm,learning,method,data,training,ˆ,valu...   \n",
       "9   speech,language,recognition,model,word,system,...   \n",
       "10  model,question,language,bert,task,answer,token...   \n",
       "11  translation,language,machine,system,source,mod...   \n",
       "12  word,model,text,classiﬁcation,document,sentime...   \n",
       "13  model,network,layer,neural,training,learning,i...   \n",
       "14  model,sentence,sequence,generation,word,attent...   \n",
       "\n",
       "                                               tokens  \n",
       "0   [multiresolution, recurrent, neural, networks,...  \n",
       "1   [adaptive, learning, sentiment, classiﬁcation,...  \n",
       "2   [e, uniﬁed, toolkit, text, retrieval, analysis...  \n",
       "3   [deep, reinforcement, learning, recommendation...  \n",
       "4   [language, model, pretraining, guillaume, lamp...  \n",
       "5   [convolutional, neural, network, language, mod...  \n",
       "6   [parsing, language, modeling, kook, choe, brow...  \n",
       "7   [learning, sentence, representations, via, mod...  \n",
       "8   [memory, networks, personalised, recommendatio...  \n",
       "9   [published, conference, paper, iclr, raternal,...  \n",
       "10  [estimating, attention, flow, online, video, n...  \n",
       "11  [linguistic, input, features, improve, neural,...  \n",
       "12  [fusing, document, collection, label, represen...  \n",
       "13  [online, learning, eﬀort, reduction, interacti...  \n",
       "14  [relational, recurrent, neural, networks, adam...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtpertpc = df.groupby('topic').agg({'doc': list, 'text': lambda x: ','.join(x), 'Topic_Keywords':'first' \n",
    "                                     }).reset_index()\n",
    "\n",
    "txtpertpc['tokens'] = txtpertpc['text'].apply(lambda x: tokenize(str(x)))\n",
    "txtpertpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401f7327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-901d0bb8a47c>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(x)\n",
      "<ipython-input-2-901d0bb8a47c>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y = np.array(y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>tokens</th>\n",
       "      <th>seqtoseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 40, 51, 52, 57, 95, 126, 139, 144, 167, 18...</td>\n",
       "      <td>multiresolution recurrent neural networks appl...</td>\n",
       "      <td>system,model,language,evaluation,score,example...</td>\n",
       "      <td>[multiresolution, recurrent, neural, networks,...</td>\n",
       "      <td>([[multiresolution, recurrent, neural, network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[80, 209, 227, 407, 437, 450, 492, 889, 1035, ...</td>\n",
       "      <td>adaptive learning sentiment classiﬁcation ruid...</td>\n",
       "      <td>model,feature,deep,data,learning,network,layer...</td>\n",
       "      <td>[adaptive, learning, sentiment, classiﬁcation,...</td>\n",
       "      <td>([[adaptive, learning, sentiment, classiﬁcatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[50, 550]</td>\n",
       "      <td>e uniﬁed toolkit text retrieval analysis sean ...</td>\n",
       "      <td>latent,variational,vae,inference,log,variable,...</td>\n",
       "      <td>[e, uniﬁed, toolkit, text, retrieval, analysis...</td>\n",
       "      <td>([[e, uniﬁed, toolkit, text, retrieval, analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3, 7, 25, 29, 38, 49, 75, 85, 142, 148, 237, ...</td>\n",
       "      <td>deep reinforcement learning recommendations xi...</td>\n",
       "      <td>user,item,recommendation,model,matrix,system,m...</td>\n",
       "      <td>[deep, reinforcement, learning, recommendation...</td>\n",
       "      <td>([[deep, reinforcement, learning, recommendati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[704, 725]</td>\n",
       "      <td>language model pretraining guillaume lample fa...</td>\n",
       "      <td>entity,relation,knowledge,graph,embeddings,tri...</td>\n",
       "      <td>[language, model, pretraining, guillaume, lamp...</td>\n",
       "      <td>([[language, model, pretraining, guillaume, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[24, 55, 68, 83, 88, 183, 218, 232, 249, 265, ...</td>\n",
       "      <td>convolutional neural network language models p...</td>\n",
       "      <td>word,model,embeddings,vector,language,sentence...</td>\n",
       "      <td>[convolutional, neural, network, language, mod...</td>\n",
       "      <td>([[convolutional, neural, network, language, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[62, 74, 78, 174, 238, 248, 290, 394, 609, 662...</td>\n",
       "      <td>parsing language modeling kook choe brown univ...</td>\n",
       "      <td>visual,feature,image,network,video,object,mult...</td>\n",
       "      <td>[parsing, language, modeling, kook, choe, brow...</td>\n",
       "      <td>([[parsing, language, modeling, kook, choe, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[67, 200, 442, 519, 565, 832]</td>\n",
       "      <td>learning sentence representations via model mu...</td>\n",
       "      <td>graph,node,tree,edge,structure,walk,parsing,fe...</td>\n",
       "      <td>[learning, sentence, representations, via, mod...</td>\n",
       "      <td>([[learning, sentence, representations, via, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[27, 30, 32, 39, 60, 76, 90, 118, 125, 234, 32...</td>\n",
       "      <td>memory networks personalised recommendation xi...</td>\n",
       "      <td>algorithm,learning,method,data,training,ˆ,valu...</td>\n",
       "      <td>[memory, networks, personalised, recommendatio...</td>\n",
       "      <td>([[memory, networks, personalised, recommendat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[66, 94, 159, 236, 325, 372, 418, 435, 451, 68...</td>\n",
       "      <td>published conference paper iclr raternal ropou...</td>\n",
       "      <td>speech,language,recognition,model,word,system,...</td>\n",
       "      <td>[published, conference, paper, iclr, raternal,...</td>\n",
       "      <td>([[published, conference, paper, iclr, raterna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[161, 201, 219, 224, 244, 268, 278, 338, 468, ...</td>\n",
       "      <td>estimating attention flow online video network...</td>\n",
       "      <td>model,question,language,bert,task,answer,token...</td>\n",
       "      <td>[estimating, attention, flow, online, video, n...</td>\n",
       "      <td>([[estimating, attention, flow, online, video,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[0, 14, 42, 99, 134, 170, 187, 262, 273, 276, ...</td>\n",
       "      <td>linguistic input features improve neural machi...</td>\n",
       "      <td>translation,language,machine,system,source,mod...</td>\n",
       "      <td>[linguistic, input, features, improve, neural,...</td>\n",
       "      <td>([[linguistic, input, features, improve, neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[5, 31, 56, 70, 77, 86, 89, 92, 102, 103, 127,...</td>\n",
       "      <td>fusing document collection label representatio...</td>\n",
       "      <td>word,model,text,classiﬁcation,document,sentime...</td>\n",
       "      <td>[fusing, document, collection, label, represen...</td>\n",
       "      <td>([[fusing, document, collection, label, repres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[15, 17, 22, 44, 63, 79, 106, 111, 120, 129, 1...</td>\n",
       "      <td>online learning eﬀort reduction interactive ne...</td>\n",
       "      <td>model,network,layer,neural,training,learning,i...</td>\n",
       "      <td>[online, learning, eﬀort, reduction, interacti...</td>\n",
       "      <td>([[online, learning, eﬀort, reduction, interac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[18, 132, 152, 212, 272, 292, 385, 386, 441, 5...</td>\n",
       "      <td>relational recurrent neural networks adam sant...</td>\n",
       "      <td>model,sentence,sequence,generation,word,attent...</td>\n",
       "      <td>[relational, recurrent, neural, networks, adam...</td>\n",
       "      <td>([[relational, recurrent, neural, networks, ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                                doc  \\\n",
       "0       0  [1, 40, 51, 52, 57, 95, 126, 139, 144, 167, 18...   \n",
       "1       1  [80, 209, 227, 407, 437, 450, 492, 889, 1035, ...   \n",
       "2       2                                          [50, 550]   \n",
       "3       3  [3, 7, 25, 29, 38, 49, 75, 85, 142, 148, 237, ...   \n",
       "4       4                                         [704, 725]   \n",
       "5       5  [24, 55, 68, 83, 88, 183, 218, 232, 249, 265, ...   \n",
       "6       7  [62, 74, 78, 174, 238, 248, 290, 394, 609, 662...   \n",
       "7       8                      [67, 200, 442, 519, 565, 832]   \n",
       "8       9  [27, 30, 32, 39, 60, 76, 90, 118, 125, 234, 32...   \n",
       "9      10  [66, 94, 159, 236, 325, 372, 418, 435, 451, 68...   \n",
       "10     11  [161, 201, 219, 224, 244, 268, 278, 338, 468, ...   \n",
       "11     12  [0, 14, 42, 99, 134, 170, 187, 262, 273, 276, ...   \n",
       "12     13  [5, 31, 56, 70, 77, 86, 89, 92, 102, 103, 127,...   \n",
       "13     14  [15, 17, 22, 44, 63, 79, 106, 111, 120, 129, 1...   \n",
       "14     15  [18, 132, 152, 212, 272, 292, 385, 386, 441, 5...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   multiresolution recurrent neural networks appl...   \n",
       "1   adaptive learning sentiment classiﬁcation ruid...   \n",
       "2   e uniﬁed toolkit text retrieval analysis sean ...   \n",
       "3   deep reinforcement learning recommendations xi...   \n",
       "4   language model pretraining guillaume lample fa...   \n",
       "5   convolutional neural network language models p...   \n",
       "6   parsing language modeling kook choe brown univ...   \n",
       "7   learning sentence representations via model mu...   \n",
       "8   memory networks personalised recommendation xi...   \n",
       "9   published conference paper iclr raternal ropou...   \n",
       "10  estimating attention flow online video network...   \n",
       "11  linguistic input features improve neural machi...   \n",
       "12  fusing document collection label representatio...   \n",
       "13  online learning eﬀort reduction interactive ne...   \n",
       "14  relational recurrent neural networks adam sant...   \n",
       "\n",
       "                                       Topic_Keywords  \\\n",
       "0   system,model,language,evaluation,score,example...   \n",
       "1   model,feature,deep,data,learning,network,layer...   \n",
       "2   latent,variational,vae,inference,log,variable,...   \n",
       "3   user,item,recommendation,model,matrix,system,m...   \n",
       "4   entity,relation,knowledge,graph,embeddings,tri...   \n",
       "5   word,model,embeddings,vector,language,sentence...   \n",
       "6   visual,feature,image,network,video,object,mult...   \n",
       "7   graph,node,tree,edge,structure,walk,parsing,fe...   \n",
       "8   algorithm,learning,method,data,training,ˆ,valu...   \n",
       "9   speech,language,recognition,model,word,system,...   \n",
       "10  model,question,language,bert,task,answer,token...   \n",
       "11  translation,language,machine,system,source,mod...   \n",
       "12  word,model,text,classiﬁcation,document,sentime...   \n",
       "13  model,network,layer,neural,training,learning,i...   \n",
       "14  model,sentence,sequence,generation,word,attent...   \n",
       "\n",
       "                                               tokens  \\\n",
       "0   [multiresolution, recurrent, neural, networks,...   \n",
       "1   [adaptive, learning, sentiment, classiﬁcation,...   \n",
       "2   [e, uniﬁed, toolkit, text, retrieval, analysis...   \n",
       "3   [deep, reinforcement, learning, recommendation...   \n",
       "4   [language, model, pretraining, guillaume, lamp...   \n",
       "5   [convolutional, neural, network, language, mod...   \n",
       "6   [parsing, language, modeling, kook, choe, brow...   \n",
       "7   [learning, sentence, representations, via, mod...   \n",
       "8   [memory, networks, personalised, recommendatio...   \n",
       "9   [published, conference, paper, iclr, raternal,...   \n",
       "10  [estimating, attention, flow, online, video, n...   \n",
       "11  [linguistic, input, features, improve, neural,...   \n",
       "12  [fusing, document, collection, label, represen...   \n",
       "13  [online, learning, eﬀort, reduction, interacti...   \n",
       "14  [relational, recurrent, neural, networks, adam...   \n",
       "\n",
       "                                             seqtoseq  \n",
       "0   ([[multiresolution, recurrent, neural, network...  \n",
       "1   ([[adaptive, learning, sentiment, classiﬁcatio...  \n",
       "2   ([[e, uniﬁed, toolkit, text, retrieval, analys...  \n",
       "3   ([[deep, reinforcement, learning, recommendati...  \n",
       "4   ([[language, model, pretraining, guillaume, la...  \n",
       "5   ([[convolutional, neural, network, language, m...  \n",
       "6   ([[parsing, language, modeling, kook, choe, br...  \n",
       "7   ([[learning, sentence, representations, via, m...  \n",
       "8   ([[memory, networks, personalised, recommendat...  \n",
       "9   ([[published, conference, paper, iclr, raterna...  \n",
       "10  ([[estimating, attention, flow, online, video,...  \n",
       "11  ([[linguistic, input, features, improve, neura...  \n",
       "12  ([[fusing, document, collection, label, repres...  \n",
       "13  ([[online, learning, eﬀort, reduction, interac...  \n",
       "14  ([[relational, recurrent, neural, networks, ad...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "txtpertpc['seqtoseq'] = txtpertpc['tokens'].apply(lambda x : build_sequences(x,10))\n",
    "txtpertpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b934570",
   "metadata": {},
   "source": [
    "# Choose a set from the prepared sequnces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc6b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>topic</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[krtalamad, zhou, cifar, senior, fellow, intro...</td>\n",
       "      <td>[zhou, cifar, senior, fellow, introduction, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[zhou, cifar, senior, fellow, introduction, re...</td>\n",
       "      <td>[cifar, senior, fellow, introduction, recurren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[cifar, senior, fellow, introduction, recurren...</td>\n",
       "      <td>[senior, fellow, introduction, recurrent, neur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[senior, fellow, introduction, recurrent, neur...</td>\n",
       "      <td>[fellow, introduction, recurrent, neural, netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[fellow, introduction, recurrent, neural, netw...</td>\n",
       "      <td>[introduction, recurrent, neural, networks, rn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tid                                              topic  \\\n",
       "0  0.0  [system, model, language, evaluation, score, e...   \n",
       "1  0.0  [system, model, language, evaluation, score, e...   \n",
       "2  0.0  [system, model, language, evaluation, score, e...   \n",
       "3  0.0  [system, model, language, evaluation, score, e...   \n",
       "4  0.0  [system, model, language, evaluation, score, e...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [krtalamad, zhou, cifar, senior, fellow, intro...   \n",
       "1  [zhou, cifar, senior, fellow, introduction, re...   \n",
       "2  [cifar, senior, fellow, introduction, recurren...   \n",
       "3  [senior, fellow, introduction, recurrent, neur...   \n",
       "4  [fellow, introduction, recurrent, neural, netw...   \n",
       "\n",
       "                                                   y  \n",
       "0  [zhou, cifar, senior, fellow, introduction, re...  \n",
       "1  [cifar, senior, fellow, introduction, recurren...  \n",
       "2  [senior, fellow, introduction, recurrent, neur...  \n",
       "3  [fellow, introduction, recurrent, neural, netw...  \n",
       "4  [introduction, recurrent, neural, networks, rn...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "train_df = pd.DataFrame({'tid':[],'topic':[],'x':[], 'y':[]})\n",
    "i=0\n",
    "for i in range(len(txtpertpc)):\n",
    " \n",
    "    train_df=train_df.append(pd.DataFrame({'tid':[i] *len(txtpertpc['seqtoseq'][i][0][200:300]),\n",
    "            'topic':[txtpertpc['Topic_Keywords'][i]] *len(txtpertpc['seqtoseq'][i][0][200:300]),\n",
    "            'x':txtpertpc['seqtoseq'][i][0][200:300].tolist(), \n",
    "            'y':txtpertpc['seqtoseq'][i][1][200:300].tolist()}))\n",
    "    \n",
    "train_df['topic']=train_df['topic'].apply(lambda x: x.split(','))\n",
    "train_df=train_df.reset_index(drop='index')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005468e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962f35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167d9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1c5c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['x'] = train_df['x'].apply(lambda x : ' '.join([t for t in x]))\n",
    "# train_df['y'] = train_df['y'].apply(lambda x : ' '.join([t for t in x]))\n",
    "# train_df['topic']=train_df['topic'].apply(func)\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d549f",
   "metadata": {},
   "source": [
    "# Vocabulary calculation and preparation\n",
    "* get all vocabulary (total unique words in corpus)\n",
    "* assign each word to id\n",
    "* assign each word to a vector by one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27c8a142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.append(train_df['x'].explode().unique(), train_df['y'].explode().unique())\n",
    "vocab = list(set(np.append(vocab, train_df['topic'].explode().unique())))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d9fe9",
   "metadata": {},
   "source": [
    "## Create Dictionary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b2a9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id to word and word to id\n",
    "id2vocab = {idx:label for idx, label in enumerate(vocab)}\n",
    "vocab2id = {label:idx for idx, label in enumerate(vocab)}\n",
    "\n",
    "# vector for each word by one-hot encoding\n",
    "total_vocab_one_hot_dict = {}\n",
    "for v in vocab:\n",
    "    total_vocab_one_hot_dict[v] = [0]*len(vocab)\n",
    "    total_vocab_one_hot_dict[v][vocab2id[v]]=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821e810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "208a41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(list_txt):\n",
    "    return [total_vocab_one_hot_dict[i] for i in list_txt]\n",
    "\n",
    "def list2ids(list_txt):\n",
    "    return [vocab2id[i] for i in list_txt]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1601fd",
   "metadata": {},
   "source": [
    "## update sequances with on-hot and ids codes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c25b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['one_hot_x'] = train_df['x'].apply(lambda x: binarize(x))\n",
    "train_df['one_hot_y'] = train_df['y'].apply(lambda x: binarize(x))\n",
    "train_df['one_hot_topic'] = train_df['topic'].apply(lambda x: binarize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75e7f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id_word_x'] = train_df['x'].apply(lambda x: list2ids(x))\n",
    "train_df['id_word_y'] = train_df['y'].apply(lambda x: list2ids(x))\n",
    "train_df['id_word_topic'] = train_df['topic'].apply(lambda x: list2ids(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1b4b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>topic</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>one_hot_x</th>\n",
       "      <th>one_hot_y</th>\n",
       "      <th>one_hot_topic</th>\n",
       "      <th>id_word_x</th>\n",
       "      <th>id_word_y</th>\n",
       "      <th>id_word_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[krtalamad, zhou, cifar, senior, fellow, intro...</td>\n",
       "      <td>[zhou, cifar, senior, fellow, introduction, re...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[614, 632, 686, 489, 301, 608, 418, 794, 664, ...</td>\n",
       "      <td>[632, 686, 489, 301, 608, 418, 794, 664, 699, ...</td>\n",
       "      <td>[722, 270, 755, 327, 757, 10, 399, 249, 3, 920]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[zhou, cifar, senior, fellow, introduction, re...</td>\n",
       "      <td>[cifar, senior, fellow, introduction, recurren...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[632, 686, 489, 301, 608, 418, 794, 664, 699, ...</td>\n",
       "      <td>[686, 489, 301, 608, 418, 794, 664, 699, 785, ...</td>\n",
       "      <td>[722, 270, 755, 327, 757, 10, 399, 249, 3, 920]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[cifar, senior, fellow, introduction, recurren...</td>\n",
       "      <td>[senior, fellow, introduction, recurrent, neur...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[686, 489, 301, 608, 418, 794, 664, 699, 785, ...</td>\n",
       "      <td>[489, 301, 608, 418, 794, 664, 699, 785, 830, ...</td>\n",
       "      <td>[722, 270, 755, 327, 757, 10, 399, 249, 3, 920]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[senior, fellow, introduction, recurrent, neur...</td>\n",
       "      <td>[fellow, introduction, recurrent, neural, netw...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[489, 301, 608, 418, 794, 664, 699, 785, 830, ...</td>\n",
       "      <td>[301, 608, 418, 794, 664, 699, 785, 830, 900, ...</td>\n",
       "      <td>[722, 270, 755, 327, 757, 10, 399, 249, 3, 920]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[system, model, language, evaluation, score, e...</td>\n",
       "      <td>[fellow, introduction, recurrent, neural, netw...</td>\n",
       "      <td>[introduction, recurrent, neural, networks, rn...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[301, 608, 418, 794, 664, 699, 785, 830, 900, ...</td>\n",
       "      <td>[608, 418, 794, 664, 699, 785, 830, 900, 450, ...</td>\n",
       "      <td>[722, 270, 755, 327, 757, 10, 399, 249, 3, 920]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tid                                              topic  \\\n",
       "0  0.0  [system, model, language, evaluation, score, e...   \n",
       "1  0.0  [system, model, language, evaluation, score, e...   \n",
       "2  0.0  [system, model, language, evaluation, score, e...   \n",
       "3  0.0  [system, model, language, evaluation, score, e...   \n",
       "4  0.0  [system, model, language, evaluation, score, e...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [krtalamad, zhou, cifar, senior, fellow, intro...   \n",
       "1  [zhou, cifar, senior, fellow, introduction, re...   \n",
       "2  [cifar, senior, fellow, introduction, recurren...   \n",
       "3  [senior, fellow, introduction, recurrent, neur...   \n",
       "4  [fellow, introduction, recurrent, neural, netw...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [zhou, cifar, senior, fellow, introduction, re...   \n",
       "1  [cifar, senior, fellow, introduction, recurren...   \n",
       "2  [senior, fellow, introduction, recurrent, neur...   \n",
       "3  [fellow, introduction, recurrent, neural, netw...   \n",
       "4  [introduction, recurrent, neural, networks, rn...   \n",
       "\n",
       "                                           one_hot_x  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                           one_hot_y  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                       one_hot_topic  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                           id_word_x  \\\n",
       "0  [614, 632, 686, 489, 301, 608, 418, 794, 664, ...   \n",
       "1  [632, 686, 489, 301, 608, 418, 794, 664, 699, ...   \n",
       "2  [686, 489, 301, 608, 418, 794, 664, 699, 785, ...   \n",
       "3  [489, 301, 608, 418, 794, 664, 699, 785, 830, ...   \n",
       "4  [301, 608, 418, 794, 664, 699, 785, 830, 900, ...   \n",
       "\n",
       "                                           id_word_y  \\\n",
       "0  [632, 686, 489, 301, 608, 418, 794, 664, 699, ...   \n",
       "1  [686, 489, 301, 608, 418, 794, 664, 699, 785, ...   \n",
       "2  [489, 301, 608, 418, 794, 664, 699, 785, 830, ...   \n",
       "3  [301, 608, 418, 794, 664, 699, 785, 830, 900, ...   \n",
       "4  [608, 418, 794, 664, 699, 785, 830, 900, 450, ...   \n",
       "\n",
       "                                     id_word_topic  \n",
       "0  [722, 270, 755, 327, 757, 10, 399, 249, 3, 920]  \n",
       "1  [722, 270, 755, 327, 757, 10, 399, 249, 3, 920]  \n",
       "2  [722, 270, 755, 327, 757, 10, 399, 249, 3, 920]  \n",
       "3  [722, 270, 755, 327, 757, 10, 399, 249, 3, 920]  \n",
       "4  [722, 270, 755, 327, 757, 10, 399, 249, 3, 920]  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9bbb1a",
   "metadata": {},
   "source": [
    "# Dataset splitting - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "270a8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.DataFrame()\n",
    "testing=pd.DataFrame()\n",
    "for i in range(16):\n",
    "    training=training.append(train_df[train_df['tid']==i].head(80))\n",
    "    testing=testing.append(train_df[train_df['tid']==i].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18b2ac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1500, 10)\n",
      "TRAIN Dataset: (1200, 10)\n",
      "VALIDATION Dataset: (120, 10)\n",
      "TEST Dataset: (180, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_size = 0.75\n",
    "# train_df = train_df.sample(frac=1)\n",
    "\n",
    "train_dataset=training\n",
    "\n",
    "testing = testing.sample(frac=1)\n",
    "\n",
    "# training dataset\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = testing.sample(frac=0.4,random_state=200)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = testing.drop(val_dataset.index).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe0b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f970ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3c1d13",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b16be",
   "metadata": {},
   "source": [
    "## Token-Position-Topic Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "965ede6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=10\n",
    "class TokenPositionTopicEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenPositionTopicEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size,\n",
    "                                          output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        \n",
    "        self.topic_emb = layers.Embedding(input_dim=vocab_size,\n",
    "                                          output_dim=embed_dim)\n",
    "        \n",
    "        \n",
    "    def call(self, x, topic):\n",
    "        # calculate embedding for tokens with their positions, and topic\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        \n",
    "        x = self.token_emb(x)\n",
    "        \n",
    "        topic_emb = self.topic_emb(topic)\n",
    "        \n",
    "        return x + positions + topic_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2dc5a",
   "metadata": {},
   "source": [
    "## Transformer Block (multi-head attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6879c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                             key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)  # attention layer\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # layer norm\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  #feed-forward layer\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)  # layer norm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fece2",
   "metadata": {},
   "source": [
    "## Build Full Model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d3357c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(embed_dim, num_heads, ff_dim, max_len, keywords_len):\n",
    "    \n",
    "    # input sequence\n",
    "    input_seq = layers.Input(shape=(max_len, ))\n",
    "    # input topic number\n",
    "    input_topic = layers.Input(shape=(keywords_len, ))\n",
    "\n",
    "    # find embeddings \n",
    "    embedding = TokenPositionTopicEmbedding(max_len, vocab_size, embed_dim)(input_seq, input_topic)\n",
    "    \n",
    "    # use a number of stracked transformer blocks \n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    \n",
    "    # dense layer with ReLu activation\n",
    "    x = layers.Dense(ff_dim, activation='relu', name='Dense_ReLu1')(x)\n",
    "    \n",
    "    # softmax layer to predict sequences\n",
    "    output = layers.Dense(vocab_size, activation='softmax', name='Dense_Softmax')(x)\n",
    "    \n",
    "    # model with its inputs and outputs\n",
    "    model = tf.keras.Model(inputs=[input_seq, input_topic], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c37e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256  # Embedding size for each token\n",
    "num_heads = 10  # Number of attention heads\n",
    "ff_dim = 80  # Hidden layer size in feed forward network inside transformer\n",
    "max_len = 10\n",
    "keywords_len = 10\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model = get_model(embed_dim, num_heads, ff_dim, max_len, keywords_len)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy', run_eagerly=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4bdb0f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " token_position_topic_embedding  (None, 10, 256)     517632      ['input_7[0][0]',                \n",
      " _3 (TokenPositionTopicEmbeddin                                   'input_8[0][0]']                \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " transformer_block_12 (Transfor  (None, 10, 256)     2671696     ['token_position_topic_embedding_\n",
      " merBlock)                                                       3[0][0]']                        \n",
      "                                                                                                  \n",
      " transformer_block_13 (Transfor  (None, 10, 256)     2671696     ['transformer_block_12[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_14 (Transfor  (None, 10, 256)     2671696     ['transformer_block_13[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_15 (Transfor  (None, 10, 256)     2671696     ['transformer_block_14[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_16 (Transfor  (None, 10, 256)     2671696     ['transformer_block_15[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_17 (Transfor  (None, 10, 256)     2671696     ['transformer_block_16[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " Dense_ReLu1 (Dense)            (None, 10, 80)       20560       ['transformer_block_17[0][0]']   \n",
      "                                                                                                  \n",
      " Dense_Softmax (Dense)          (None, 10, 1006)     81486       ['Dense_ReLu1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,649,854\n",
      "Trainable params: 16,649,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d389e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9efe5563",
   "metadata": {},
   "source": [
    "# Training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f926bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq =  train_dataset['id_word_x'].tolist()\n",
    "input_seq = np.array(input_seq, dtype=np.int32)\n",
    "\n",
    "y_train = np.array(train_dataset['one_hot_y'].tolist(), dtype=np.int32)\n",
    "\n",
    "val_input_seq =  val_dataset['id_word_x'].tolist()\n",
    "val_input_seq = np.array(val_input_seq, dtype=np.int32)\n",
    "\n",
    "y_val = np.array(val_dataset['one_hot_y'].tolist(), dtype=np.int32)\n",
    "\n",
    "\n",
    "input_topic = train_dataset['id_word_topic'].tolist()\n",
    "input_topic = np.array(input_topic, dtype=np.int32)\n",
    "\n",
    "val_input_topic = val_dataset['id_word_topic'].tolist()\n",
    "val_input_topic = np.array(val_input_topic, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480729c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f6bf32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.8443 - accuracy: 0.0022\n",
      "4/4 [==============================] - 2s 437ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.8288 - accuracy: 0.0033\n",
      "4/4 [==============================] - 2s 502ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "19/19 [==============================] - 44s 2s/step - loss: 6.8107 - accuracy: 0.0034\n",
      "4/4 [==============================] - 2s 432ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.7867 - accuracy: 0.0052\n",
      "4/4 [==============================] - 2s 492ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.7630 - accuracy: 0.0073\n",
      "4/4 [==============================] - 2s 435ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 5 ==================================================\n",
      "19/19 [==============================] - 44s 2s/step - loss: 6.7329 - accuracy: 0.0104\n",
      "4/4 [==============================] - 2s 452ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 6 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.7024 - accuracy: 0.0114\n",
      "4/4 [==============================] - 2s 439ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 7 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.6674 - accuracy: 0.0171\n",
      "4/4 [==============================] - 2s 406ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 8 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.6312 - accuracy: 0.0198\n",
      "4/4 [==============================] - 2s 446ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 9 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.5970 - accuracy: 0.0213\n",
      "4/4 [==============================] - 2s 424ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 10 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.5615 - accuracy: 0.0258\n",
      "4/4 [==============================] - 2s 418ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 11 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.5219 - accuracy: 0.0263\n",
      "4/4 [==============================] - 2s 455ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 12 ==================================================\n",
      "19/19 [==============================] - 44s 2s/step - loss: 6.4843 - accuracy: 0.0305\n",
      "4/4 [==============================] - 2s 433ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 13 ==================================================\n",
      "19/19 [==============================] - 42s 2s/step - loss: 6.4484 - accuracy: 0.0337\n",
      "4/4 [==============================] - 2s 439ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 14 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.4079 - accuracy: 0.0363\n",
      "4/4 [==============================] - 2s 417ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 15 ==================================================\n",
      "19/19 [==============================] - 43s 2s/step - loss: 6.3693 - accuracy: 0.0413\n",
      "4/4 [==============================] - 2s 410ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 16 ==================================================\n",
      "19/19 [==============================] - 264s 15s/step - loss: 6.3297 - accuracy: 0.0439\n",
      "4/4 [==============================] - 1s 258ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 17 ==================================================\n",
      "19/19 [==============================] - 648s 36s/step - loss: 6.2956 - accuracy: 0.0451\n",
      "4/4 [==============================] - 1s 278ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 18 ==================================================\n",
      "19/19 [==============================] - 647s 36s/step - loss: 6.2551 - accuracy: 0.0492\n",
      "4/4 [==============================] - 1s 339ms/step\n",
      "validation accuracy:  0.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 19 ==================================================\n",
      "19/19 [==============================] - 640s 35s/step - loss: 6.2211 - accuracy: 0.0532\n",
      "4/4 [==============================] - 3s 861ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "for epoch in range(20):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=64)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred[i]))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred[i]))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eaf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7877232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "38/38 [==============================] - 41s 1s/step - loss: 6.1697 - accuracy: 0.0562\n",
      "4/4 [==============================] - 1s 319ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "38/38 [==============================] - 40s 1s/step - loss: 6.1014 - accuracy: 0.0617\n",
      "4/4 [==============================] - 1s 302ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "38/38 [==============================] - 43s 1s/step - loss: 6.0385 - accuracy: 0.0658\n",
      "4/4 [==============================] - 1s 294ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "38/38 [==============================] - 37s 971ms/step - loss: 5.9757 - accuracy: 0.0699\n",
      "4/4 [==============================] - 1s 323ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "38/38 [==============================] - 40s 1s/step - loss: 5.9143 - accuracy: 0.0753\n",
      "4/4 [==============================] - 1s 326ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 5 ==================================================\n",
      "38/38 [==============================] - 42s 1s/step - loss: 5.8566 - accuracy: 0.0784\n",
      "4/4 [==============================] - 1s 335ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 6 ==================================================\n",
      "38/38 [==============================] - 47s 1s/step - loss: 5.7987 - accuracy: 0.0822\n",
      "4/4 [==============================] - 2s 380ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 7 ==================================================\n",
      "38/38 [==============================] - 43s 1s/step - loss: 5.7431 - accuracy: 0.0875\n",
      "4/4 [==============================] - 1s 331ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 8 ==================================================\n",
      "38/38 [==============================] - 44s 1s/step - loss: 5.6893 - accuracy: 0.0908\n",
      "4/4 [==============================] - 1s 356ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 9 ==================================================\n",
      "38/38 [==============================] - 42s 1s/step - loss: 5.6363 - accuracy: 0.0940\n",
      "4/4 [==============================] - 1s 335ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 10 ==================================================\n",
      "38/38 [==============================] - 42s 1s/step - loss: 5.5854 - accuracy: 0.0957\n",
      "4/4 [==============================] - 1s 327ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 11 ==================================================\n",
      "38/38 [==============================] - 42s 1s/step - loss: 5.5371 - accuracy: 0.1001\n",
      "4/4 [==============================] - 1s 347ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 12 ==================================================\n",
      "38/38 [==============================] - 43s 1s/step - loss: 5.4892 - accuracy: 0.1030\n",
      "4/4 [==============================] - 1s 341ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 13 ==================================================\n",
      "38/38 [==============================] - 43s 1s/step - loss: 5.4377 - accuracy: 0.1066\n",
      "4/4 [==============================] - 1s 171ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 14 ==================================================\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 5.3915 - accuracy: 0.1090\n",
      "4/4 [==============================] - 1s 172ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 15 ==================================================\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 5.3421 - accuracy: 0.1129\n",
      "4/4 [==============================] - 1s 172ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 16 ==================================================\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 5.2936 - accuracy: 0.1201\n",
      "4/4 [==============================] - 1s 171ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 17 ==================================================\n",
      "38/38 [==============================] - 23s 597ms/step - loss: 5.2470 - accuracy: 0.1197\n",
      "4/4 [==============================] - 1s 188ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 18 ==================================================\n",
      "38/38 [==============================] - 24s 641ms/step - loss: 5.1981 - accuracy: 0.1257\n",
      "4/4 [==============================] - 1s 208ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 19 ==================================================\n",
      "38/38 [==============================] - 27s 698ms/step - loss: 5.1571 - accuracy: 0.1262\n",
      "4/4 [==============================] - 1s 192ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=32)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred[i]))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred[i]))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4cf21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "75/75 [==============================] - 32s 425ms/step - loss: 4.5116 - accuracy: 0.1918\n",
      "4/4 [==============================] - 1s 174ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "75/75 [==============================] - 36s 479ms/step - loss: 4.4314 - accuracy: 0.2042\n",
      "4/4 [==============================] - 1s 242ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "75/75 [==============================] - 34s 458ms/step - loss: 4.3493 - accuracy: 0.2155\n",
      "4/4 [==============================] - 1s 174ms/step\n",
      "validation accuracy:  0.1\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "75/75 [==============================] - 32s 429ms/step - loss: 4.2667 - accuracy: 0.2284\n",
      "4/4 [==============================] - 1s 187ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "75/75 [==============================] - 35s 463ms/step - loss: 4.1872 - accuracy: 0.2454\n",
      "4/4 [==============================] - 1s 230ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 5 ==================================================\n",
      "75/75 [==============================] - 46s 621ms/step - loss: 4.0980 - accuracy: 0.2592\n",
      "4/4 [==============================] - 1s 260ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 6 ==================================================\n",
      "75/75 [==============================] - 51s 683ms/step - loss: 4.0148 - accuracy: 0.2752\n",
      "4/4 [==============================] - 1s 261ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 7 ==================================================\n",
      "75/75 [==============================] - 40s 533ms/step - loss: 3.9276 - accuracy: 0.2932\n",
      "4/4 [==============================] - 1s 235ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 8 ==================================================\n",
      "75/75 [==============================] - 40s 525ms/step - loss: 3.8424 - accuracy: 0.3116\n",
      "4/4 [==============================] - 1s 234ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 9 ==================================================\n",
      "75/75 [==============================] - 40s 527ms/step - loss: 3.7546 - accuracy: 0.3286\n",
      "4/4 [==============================] - 1s 234ms/step\n",
      "validation accuracy:  0.4\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 10 ==================================================\n",
      "75/75 [==============================] - 39s 523ms/step - loss: 3.6696 - accuracy: 0.3524\n",
      "4/4 [==============================] - 1s 237ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 11 ==================================================\n",
      "75/75 [==============================] - 40s 530ms/step - loss: 3.5778 - accuracy: 0.3755\n",
      "4/4 [==============================] - 1s 249ms/step\n",
      "validation accuracy:  0.3\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 12 ==================================================\n",
      "75/75 [==============================] - 40s 539ms/step - loss: 3.4913 - accuracy: 0.3956\n",
      "4/4 [==============================] - 1s 312ms/step\n",
      "validation accuracy:  0.4\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 13 ==================================================\n",
      "75/75 [==============================] - 43s 573ms/step - loss: 3.3988 - accuracy: 0.4226\n",
      "4/4 [==============================] - 1s 233ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 14 ==================================================\n",
      "75/75 [==============================] - 40s 537ms/step - loss: 3.3108 - accuracy: 0.4467\n",
      "4/4 [==============================] - 1s 243ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 15 ==================================================\n",
      "75/75 [==============================] - 41s 542ms/step - loss: 3.2172 - accuracy: 0.4696\n",
      "4/4 [==============================] - 1s 242ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 16 ==================================================\n",
      "75/75 [==============================] - 41s 540ms/step - loss: 3.1298 - accuracy: 0.4933\n",
      "4/4 [==============================] - 1s 254ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 17 ==================================================\n",
      "75/75 [==============================] - 42s 557ms/step - loss: 3.0381 - accuracy: 0.5197\n",
      "4/4 [==============================] - 1s 239ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 18 ==================================================\n",
      "75/75 [==============================] - 42s 553ms/step - loss: 2.9474 - accuracy: 0.5474\n",
      "4/4 [==============================] - 1s 246ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 19 ==================================================\n",
      "75/75 [==============================] - 41s 548ms/step - loss: 2.8587 - accuracy: 0.5702\n",
      "4/4 [==============================] - 1s 242ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 20 ==================================================\n",
      "75/75 [==============================] - 35s 469ms/step - loss: 2.7699 - accuracy: 0.6024\n",
      "4/4 [==============================] - 1s 195ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 21 ==================================================\n",
      "75/75 [==============================] - 33s 436ms/step - loss: 2.6837 - accuracy: 0.6218\n",
      "4/4 [==============================] - 1s 187ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 22 ==================================================\n",
      "75/75 [==============================] - 32s 430ms/step - loss: 2.5937 - accuracy: 0.6463\n",
      "4/4 [==============================] - 1s 195ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 23 ==================================================\n",
      "75/75 [==============================] - 33s 434ms/step - loss: 2.5054 - accuracy: 0.6737\n",
      "4/4 [==============================] - 1s 177ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 24 ==================================================\n",
      "75/75 [==============================] - 195s 3s/step - loss: 2.4186 - accuracy: 0.6992\n",
      "4/4 [==============================] - 1s 187ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 25 ==================================================\n",
      "75/75 [==============================] - 32s 427ms/step - loss: 2.3374 - accuracy: 0.7202\n",
      "4/4 [==============================] - 1s 163ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 26 ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 31s 410ms/step - loss: 2.2509 - accuracy: 0.7440\n",
      "4/4 [==============================] - 1s 179ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 27 ==================================================\n",
      "75/75 [==============================] - 31s 408ms/step - loss: 2.1686 - accuracy: 0.7642\n",
      "4/4 [==============================] - 1s 175ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 28 ==================================================\n",
      "75/75 [==============================] - 32s 429ms/step - loss: 2.0887 - accuracy: 0.7812\n",
      "4/4 [==============================] - 1s 201ms/step\n",
      "validation accuracy:  0.5\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 29 ==================================================\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 2.0065 - accuracy: 0.7997\n",
      "4/4 [==============================] - 1s 167ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 30 ==================================================\n",
      "75/75 [==============================] - 31s 407ms/step - loss: 1.9282 - accuracy: 0.8201\n",
      "4/4 [==============================] - 1s 180ms/step\n",
      "validation accuracy:  0.7\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 31 ==================================================\n",
      "75/75 [==============================] - 32s 423ms/step - loss: 1.8510 - accuracy: 0.8386\n",
      "4/4 [==============================] - 1s 187ms/step\n",
      "validation accuracy:  0.7\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 32 ==================================================\n",
      "75/75 [==============================] - 36s 478ms/step - loss: 1.7803 - accuracy: 0.8513\n",
      "4/4 [==============================] - 1s 204ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 33 ==================================================\n",
      "75/75 [==============================] - 36s 480ms/step - loss: 1.7071 - accuracy: 0.8668\n",
      "4/4 [==============================] - 1s 219ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 34 ==================================================\n",
      "75/75 [==============================] - 38s 500ms/step - loss: 1.6340 - accuracy: 0.8817\n",
      "4/4 [==============================] - 1s 196ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 35 ==================================================\n",
      "75/75 [==============================] - 37s 494ms/step - loss: 1.5639 - accuracy: 0.8954\n",
      "4/4 [==============================] - 1s 205ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 36 ==================================================\n",
      "75/75 [==============================] - 36s 475ms/step - loss: 1.4997 - accuracy: 0.9049\n",
      "4/4 [==============================] - 1s 188ms/step\n",
      "validation accuracy:  0.9\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 37 ==================================================\n",
      "75/75 [==============================] - 33s 443ms/step - loss: 1.4340 - accuracy: 0.9154\n",
      "4/4 [==============================] - 1s 210ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 38 ==================================================\n",
      "75/75 [==============================] - 35s 465ms/step - loss: 1.3687 - accuracy: 0.9251\n",
      "4/4 [==============================] - 1s 199ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 39 ==================================================\n",
      "75/75 [==============================] - 34s 448ms/step - loss: 1.3101 - accuracy: 0.9312\n",
      "4/4 [==============================] - 1s 190ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=16)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b018314b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "75/75 [==============================] - 31s 414ms/step - loss: 1.2495 - accuracy: 0.9410\n",
      "4/4 [==============================] - 1s 166ms/step\n",
      "validation accuracy:  0.8\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "75/75 [==============================] - 31s 412ms/step - loss: 1.1936 - accuracy: 0.9459\n",
      "4/4 [==============================] - 1s 191ms/step\n",
      "validation accuracy:  0.9\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "75/75 [==============================] - 32s 421ms/step - loss: 1.1422 - accuracy: 0.9512\n",
      "4/4 [==============================] - 1s 168ms/step\n",
      "validation accuracy:  1.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "75/75 [==============================] - 31s 415ms/step - loss: 1.0873 - accuracy: 0.9560\n",
      "4/4 [==============================] - 1s 175ms/step\n",
      "validation accuracy:  1.0\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 1.0365 - accuracy: 0.9603\n",
      "4/4 [==============================] - 1s 166ms/step\n",
      "validation accuracy:  1.0\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=16)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "50b9ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "75/75 [==============================] - 31s 410ms/step - loss: 0.9883 - accuracy: 0.9636\n",
      "4/4 [==============================] - 1s 175ms/step\n",
      "validation accuracy:  0.9\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "75/75 [==============================] - 31s 407ms/step - loss: 0.9446 - accuracy: 0.9671\n",
      "4/4 [==============================] - 1s 175ms/step\n",
      "validation accuracy:  0.9\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "75/75 [==============================] - 33s 438ms/step - loss: 0.8988 - accuracy: 0.9685\n",
      "4/4 [==============================] - 1s 289ms/step\n",
      "validation accuracy:  0.9083333333333333\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "75/75 [==============================] - 33s 443ms/step - loss: 0.8574 - accuracy: 0.9727\n",
      "4/4 [==============================] - 1s 181ms/step\n",
      "validation accuracy:  0.9083333333333333\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "75/75 [==============================] - 34s 449ms/step - loss: 0.8170 - accuracy: 0.9733\n",
      "4/4 [==============================] - 1s 196ms/step\n",
      "validation accuracy:  0.9083333333333333\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=16)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e34381d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH = 0 ==================================================\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 0.7750 - accuracy: 0.9762\n",
      "4/4 [==============================] - 1s 184ms/step\n",
      "validation accuracy:  0.9166666666666666\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 1 ==================================================\n",
      "75/75 [==============================] - 32s 424ms/step - loss: 0.7393 - accuracy: 0.9763\n",
      "4/4 [==============================] - 1s 184ms/step\n",
      "validation accuracy:  0.925\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 2 ==================================================\n",
      "75/75 [==============================] - 36s 481ms/step - loss: 0.7071 - accuracy: 0.9787\n",
      "4/4 [==============================] - 1s 173ms/step\n",
      "validation accuracy:  0.9333333333333333\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 3 ==================================================\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 0.6731 - accuracy: 0.9797\n",
      "4/4 [==============================] - 1s 174ms/step\n",
      "validation accuracy:  0.9333333333333333\n",
      "==========================================================================\n",
      "\n",
      "==== EPOCH = 4 ==================================================\n",
      "75/75 [==============================] - 31s 408ms/step - loss: 0.6405 - accuracy: 0.9815\n",
      "4/4 [==============================] - 1s 174ms/step\n",
      "validation accuracy:  0.9333333333333333\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f'==== EPOCH = {epoch} ==================================================')\n",
    "\n",
    "    # train model using train dataset\n",
    "    history = model.fit( [input_seq,input_topic], y_train, epochs= 1, verbose=1, batch_size=16)   \n",
    "\n",
    "    train_acc.append(history.history['accuracy'][0])\n",
    "    train_loss.append(history.history['loss'][0]) \n",
    "\n",
    "\n",
    "    # prediction and validation     \n",
    "    y_pred = model.predict([val_input_seq, val_input_topic], verbose=1)\n",
    "    # validation loss \n",
    "    val_loss.append(np.array(loss( y_val, y_pred)).mean()) \n",
    "\n",
    "    true=[np.argmax(y_pred[i][-1]) for i in range(len(y_pred))]\n",
    "    pred=[np.argmax(y_val[i][-1]) for i in range(len(y_pred))]\n",
    "    total=0\n",
    "    val_acc.append(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred))\n",
    "    print('validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "    print(f'==========================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ec3a742b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b1014f",
   "metadata": {},
   "source": [
    "## Validation and Training Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "86177b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEXCAYAAACtTzM+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABEfklEQVR4nO3dd3iUVdrA4d9MJr2SHkJHOgQQRAQBQaQkBBBQilIWZe24uGsv2LCw+uEua1nUdUUBwUYTAyqyikGUIr0KoaSH1Emmv+f7I2QgJiEkZFKf+7q8zLz1OZMwz5zynqNTSimEEEI0efq6DkAIIUT9IAlBCCEEIAlBCCHEeZIQhBBCAJIQhBBCnCcJQQghBCAJQTQAZ8+epVOnTtx+++1l9j322GN06tSJ7OzsKl3zrrvu4osvvrjkMdu3b2fMmDEV7n/llVfo3r07aWlpVbq3EPWVJATRIHh6enLy5EmSk5Od24qKiti1a1edxGOxWFi9ejUjR47k448/rpMYhKhpkhBEg+Dm5sbo0aNZt26dc9umTZu48cYbSx23cuVKxowZw9ixY5k9ezYnT54EID09nT/96U/ExcUxZ84cMjMznef8/vvvzJ49mwkTJjBu3Dg+++yzSuP56quvaNWqFbNmzWLVqlWYTCbnvpMnTzJ9+nTi4uKIj49nw4YNl9w+bNgw9u3b5zy/5PXZs2cZMmQIs2fPZuTIkWRkZPDOO+9wyy23EB8fz/Dhw/nmm28AsNvtvPzyy4wcOZLY2FiefPJJrFYrI0eO5KeffnJe+8knn+TDDz+87PddNDFKiHruzJkzqlevXmrfvn1q1KhRzu0zZ85UR44cUR07dlTnzp1TiYmJavjw4ercuXNKKaU+//xzNXr0aKVpmrr33nvVokWLlFJKJSUlqV69eqnPP/9c2Ww2FRsbq/bv36+UUio/P1+NHj1a7d69W/38888qLi6u3JgmTpyoPvroI6WUUrGxsWrZsmXOfePHj1cff/yxUkqplJQUdeONN6qCgoIKtw8dOlTt3bvXeX7J6zNnzqiOHTuqX3/9VSml1NmzZ9X06dOVyWRSSim1fv16NWbMGKWUUh9++KG67bbblMlkUg6HQz344IPqyy+/VB988IGaO3euUkqpgoIC1b9/f5WXl3cFvw3RmBnqOiEJcbm6d++Om5sb+/fvJyQkhMLCQjp27Ojc/+OPPxIbG0twcDAAEyZMYMGCBZw9e5bExEQeffRRAFq3bs21114LQFJSEqdPn+aJJ55wXsdsNnPw4EHat29fbhwHDhzg8OHDxMXFATB+/HiWLl3K1KlTycvL4/Dhw9xyyy0AREVF8e2335Kbm1vu9soYDAZ69eoFQHR0NAsXLmTdunWcOnWKPXv2UFhYCEBiYiLjxo3Dy8sLgDfeeAOA/Px83nzzTbKzs0lISOCGG24gICCg8jdbNEmSEESDMnbsWNauXUtwcDDjxo0rtU/TtDLHK6Ww2+3odDrURdN2GQzFf/oOhwN/f3/WrFnj3JeVlYW/vz+//fZbuTEsW7YMg8HAxIkTgeLmmoyMDH744Qf69OkDgE6ncx5/4sQJwsLCyt3evHlzZ5wlrFar82cPDw9nrAcOHODee+9l1qxZDBw4kGuuuYbnnnuuVHkuLoOmaYSHhzNq1CjWrl3LunXrmD9/frllEgKkD0E0MOPGjSMhIYENGzaUGQE0aNAgNmzY4Bxx9PnnnxMUFETr1q0ZNGgQK1euBCAlJYXt27cD0LZtW7y8vJwJITU1lTFjxrB///5y75+fn8+GDRt455132Lx5M5s3b+aHH35g7NixfPjhh/j5+dGtWzdWr17tvN7UqVMxm83lbi8oKCA4ONh5v+3bt5fq37jYr7/+Svfu3fnTn/5Ev379+O6773A4HABcd911rF+/HqvViqZpPPvss3z11VcA3HbbbSxduhSlFDExMdV520UTITUE0aBERETQvn17/P39CQoKKrVv4MCBzJo1i5kzZ6JpGsHBwfz73/9Gr9czf/58Hn/8cUaPHk1kZCSdO3cGir+Bv/XWWyxYsID33nsPu93Ogw8+SJ8+fZxJ42Jffvkl7du3p3///qW233PPPcTFxXH06FFef/11nnvuOT766CN0Oh0LFiwgLCyswu1/+9vfePbZZ1m5ciXdunWjW7du5ZZ9zJgxbNq0idGjR6NpGkOHDiUvLw+j0ciUKVNITk5mwoQJKKXo168f06dPB6Bz584EBgYyZcqUGvgNiMZMp5RMfy1EY3b69GmmT59OQkIC3t7edR2OqMekhiBEI/aPf/yDVatW8dxzz0kyEJWSGoIQQghAOpWFEEKcJwlBCCEEIAlBCCHEeZIQhBBCAA18lFFOTiGaVvU+8ZAQP86dM7ogovqtqZYbmm7ZpdxNS2Xl1ut1NGvmW+F+lyaEkgdm3nnnHVq0aFFq36FDh3jyyScpLCykb9++PPfcc2Uev6+MpqlqJYSSc5uiplpuaLpll3I3LVdSbpc1Ge3Zs4epU6eSlJRU7v6HH36YZ555ho0bN6KUYtWqVa4KRQghxGVwWUJYtWoV8+fPJzw8vMy+5ORkzGazcxbHCRMmkJCQ4KpQhBBCXAaXNRktWLCgwn0ZGRnO2R8BwsLCSE9Pr5H7KqXIycnEajUD5VedMjL05c6M2djV33Lr8PDwolmzsFKzgQohaleddCprmlbqH75SqlofBCEhfmW2ZWRkYDDoCQtrhU4ng6gaAqU0srOzADNhYWVrlDUlLMzfZdeuz6TcTcuVlLtOEkJkZGSpKX6zsrLKbVqqzLlzxjIdKJmZ5wgOjqB4VuDyvw0bDHrs9vr4Tdm16nO5fX0DycxMR6dzzXw7YWH+ZGYWuOTa9ZmUu2mprNx6va7cL9LO/a4IqjLR0dF4enqyc+dOANasWcPgwYNr5Nqa5sDNrUGPpm2S3NwMaJqjrsMQokmr1U/OOXPmMHfuXHr06MFrr73GU089hdFopFu3bsyYMaPG7iPt0A2P/M6EALtDIzPXRFp2EZm5ZgpNNorMdgrNNrLzzZzLt1BksTHvll5c1SKwxu/v8oSwefNm58/vvvuu8+fOnTvz2Wefufr2der1119l37492O02zp49Q5s27QC45ZYpxMWNvaxrzJo1jf/+d7krwxRCuFh2vpn0HBMWmwOrzUFOgYUzGUbOZBjJyjOjKYXSFDaHxsXzT+sAb08Dvt4Gmvl70bFlIOHNfGgeWvHDZVdC2lZc6K9/LV7UPTU1hQceuKtaH+ySDIRoOIrMdrLzzeQVWck3WjmRks/+pGzSs4vKHBvo50HLcD86tgjCzU2HXqfD3aAnvJk3kcE+hDfzxtfbHX0t1p4lIdSRSZPi6dq1O8eOHeGtt95j1aoV7Nz5K/n5+YSGhvL88y8THBzC9df3ZevWHbz//r/JysrkzJnTpKenMWbMOGbOvKPUNQsLjbz88gtkZmaQlZVJ3779eOyxpwF4++3F/PjjFtzc3Bg7dgK33jqVY8eOsHDhS1gsZgICAnnmmRc4e/YM//nPEv71ryUALFjwLL1796F37z789a8PEBgYhKenJwsWLLzkvX74YQsGQ/G9Bgy4nrlz7+azz9ah1+vZtWsHy5Yt5fXX/1mbb7kQLrHraCZ7fz/H78l5JGcVltrn4a6nU8tmDO3VnJbhfnh6GPD0cCPAxx1/H486irhijToh/LQvla17U8ts1+ngSpcFuj4mioE9oq7oGv37D+D551/m7NkznD6dxDvv/Ae9Xs8LLzzDxo1fM3Xq7aWOP378GG+99R5GYwG33jqeCRNuxd//whCzxMStdOjQkRdffBWbzcbtt9/CkSOHSUlJZt++PSxbtgqz2cq9997JjTfexHPPPc099zzAwIGD+PLLz/j000+47rqBFcZ7+vQpPv10MVFRzfnmm4RL3mvp0k+w2+3OezVvHs3u3Tvp0+caEhK+IjZ2zBW9d0LUB9/uOMPyb4/h7WmgfXQA13QOJzLEh0BfDwJ8PQgN9Mbd0HCGvzfqhFDfde3aHYAWLVpy//3zWLduNadPn+LAgX1ER7coc/zVV/fF3d2dZs2CCQgIoLDQWCoh3HTTKA4e3M+qVctJSjpJXl4eJlMRv/22k2HDbsLDwwO93sB//7uc3Nxczp3LYuDAQQDcfPMkAHbt2lFhvM2aBRMV1fyy7+Xh4eFs8oqLG8vGjRvo1q0HO3f+yl//+ljNvIlC1JHdRzNZ8e0xel0Vyn0TuuOmbzgf/BVp1AlhYI/yv8XXl/H4np6eABw+fIhnn32SKVOmMXTojbi56SlvZVMPjwtVTJ1OV+aYzz77hC1bNjN27M1MmtSPkyd/RymFwWDg4mbI1NQU/P0DSo3ssVgsZGVllhntY7fby8Rb1XsFBTVj6NDhLFnyFt9//y3XXTew1LWEaGhOpOTz77UHaBMVwF3jujWKZACyHkK98NtvO+nduw/jx0+iZctWJCZurdYUE7/+up2xYycwYsRorFYrx44dRdM0eva8mi1bNmO32zCbzfz1rw+QnX2OsLBwfvnlZwA2btzA++//m8DAIFJSkrFYLOTn57Fnz+5q3svuvFdmZgZeXl707z+AJUveYvTo+Ct6v4SoC0opTqTk8+mW4yxa9RsBvh48OCkGT3e3ug6txjTqGkJDceONI3jiiYeZMWMyAJ06dSE1NaXK17n11mm89trLfPzxB/j6+tG9ewypqSnEx4/n8OGDzJx5Gw6Hxi23TKVVq9Y888wLvPbay7z11j8JDAzi6aefJzQ0lOuuG8j06bcSFdWcnj17V+tes2ffhqYp571Kyrlv3x66dete/TdLiFqmlOLnA+l88cPvnMu34KbX0blVELeN6ESAb/3rGL4SOlVe20QDUd7UFWlpp4iMbH3J8+pLk1Ftq8tyOxwOlix5i2bNmjFlyu3lHnM5v7vqkqkMmpaaKndmromPNh5h/8ls2kYFcGOfaHpeFYqvl3sNRFkx5bDhSDnE+Tl4SjO449a8K7pymqmudOoKqSGIWnHnndMJDAzi1Vf/r65DEaJSp9ML+GFPClv3paLT6bjtpo4M7R2NXu/aZwKU0rAf/xnLr5+jjOcqPM479m8YWtR8TVsSgqgVH3wgD9iJ+m/P8SzWbD1JUloBBjc913QOZ+KQdgQHeLn0vkopHGf3YfnlU7RzZ9CHtMZrwO3o/JqVPdjNHbdm0S6JQxKCEKLJyymwsOLbo+w4kklEsA9Th3fgum6R+Hm7tmkIwJF5Esv2VThSDqHzD8Nr2N0Y2verk+n7JSEIIZospRQ/7Elh1ffHsdkVEwa3Y9S1rTC4uf7DWMtLx/Lr59hP/ILOyx/PAbfh3mUoujqcrVkSghCiScopsPDB14fYfyKbLq2bMWNUJyKa+dTY9bX8DLT8jHL32ZN2Yzu0Bdzc8Lh6HB4xo9B5uGYtkKqQhCCEaFKUUiTuT2PFt8ewa1pxh/HV0TU2iZxmzMa680tsR7dWPEeOTo975yF49BmH3ieoRu5bEyQhCCGajJSsQj7edARryhEGhhoYNjaOiOCq1QqU5sC640uUxVh2n82C/eQOUAr37iMwtO1D8STWpen9gtH7hVS3GC4jCcGF7rnnDiZOvJXhw0c6t5lMJiZOHMPy5Z8TFBRU5pyS2UX79evPK6+8wGuvlZ0RtGQGVCHE5VFKsX7bKdZuPYmXhxuPRx8lQMvDL/iWKl9Ly0rC+tt68PRFp//jU8o6DO2uwbPvzej9w2om+FokCcGF4uLGsmlTQqmE8L//bebqq/uWmwwuFhoaVm4yEEJUjd2h8WHCYX7al0a/LuFMG94R/ZdfoIpyUTYLOveqzaul5aYB4DvuafRBka4Iuc406oRgO/oTtiM/lNle3sRwVeXeaTDuHSueKhpg2LCbePPNf5Cfn0dAQPFydxs3buDWW6exe/dOlix5C4vFTEGBkblz5zFo0A3Oc0sW1fnss3Wkpqbw/PNPYzKZKpz2ITMzg5dffgGjsYCsrExiY+O58867sVgs/N//vcrevb/h7u7OzJl3cOONI/j11+38619voJRGZGQU8+e/yP/+9z27d+/kySefBeD++//M7Nl/BuDtt/+Jw6HRrl177rrrvkrvZTAYmDXrTgIDg3j//Xd4++3/ALBhwzoOHtzP3/72+BW9/0JcDrPVzlur97P/RDbjrm/L2IFtwGbGWJQLgJaXhlto1Z6O13JTQeeGLiC05gOuY406IdQ1Hx8fBg0awubN3zJ+/ESysjI5ffoU/fr1Z/78x3nssadp3boNO3f+yj/+8VqphHCxRYsWEhsbT3z8eBISvmLNmi/KHPPNNxu56aaRjB49BqPRyIQJcUyaNIUNG9ZiMplYtuwzCgpyue++uxk06Aaef/5p/u//FtOhQyfeeedffP31enx8Kl6W78yZ03z22Xr8/PxYvvyjSu+Vk5PNgw/ey3/+8zFZWedITj5LdHQLEhK+4q677q+pt1iIChlNNhat+o1TaUZmje7M4J7FU7c7ci+skaLlplYrIegDw9HpG9/HZ+Mr0UXcOw4s91t8bc7pExsbz3vvvcP48RPZtOlrRo6Mxc3NjaeffoHExB/5/vtvOXBgHyaTqcJr7N69k2efXQDAiBGjeeWVF8ocM23adHbt2sHy5R9x8uTv52c2NfHbb7sYO/Zm9Ho9ISGhfPzxKg4fPkhYWBgdOnQC4O67iz+gN2xYV2EMLVu2xs/Pr8r3Ahg9Oo6NGzcQGzuW7OxsmdxOuFxugYWFy3eRlm3i/gk96NXhwrd57Q8Joaq0vFT0gY2rqaiETH/tYr16Xc25c1mkp6excePXxMWNBeC+++Zw6NABOnXqzIwZsytpwtI5J/HT6XToy3RkweLFi/j000+IjIxi5sw7CAwMQimFm5uBi0c5nD17psw2o9FIRkZ6maY0h6P8tRCqci+bzUZsbDzffbeJb79NYNSo2Mt854SonpwCC4+/tZWMXBN/uSWmVDKA4mYidHp0vsHFP1eB0hxoeRnog65stcT6ShJCLRg1Ko6lS/9DQEAA0dEtyM/P48yZU9xxx9307z+QH3/83yXXP+jbtx8bN24AijulrVZLmWN27NjOtGnTGTZsOKdPnyIzMwNN0+jVqzebN3+DUors7Gzuv//PREdHk5ubw8mTJwBYtuxDVq/+nMDAIE6dOolSipSUZI4fP15uPJdzr5yc4nvZbFYiI6MICwtn9erPGTUqrgbeUSHKl51v5tVluziXZ+ahW3vRtU1wmWO03FR0AWHog6OrXENQBVmg2RttQmjUTUb1RWxsPJMmxfP4488AEBAQyJgx45g+/VYMBgNXX30NZrO5wmajhx56hBdeeIa1a7+kc+cu5bb13377LF544Rk8PT0JD4+kc+eupKQkc/PNt/DGG39n1qypAMyb9zA+Pr48/fTzvPjifOx2G82bt+Dpp5/HYDDw1VdrmDp1Iq1btyYmple58VT1XgDDh49gy5bNhIY2vKF4omHIzjfz6vJdGE02XrhrAME+5c9DpOWmoQ+MQh8Qji31CEpplz1vkJZXnEAaa0KQ9RCakLoqt91u54UXnmHYsOEMGTKswuNkPYSa11TKnZ1vZuHy3RSYrDw0uRf9e7Yot9xK0zB+8Gfcuw1HHxCOZetSfKe9ftkPiVn3fo3l55X4zfgXOq+K1xWoK1e6HoI0GQmXUkoxfvxo9Hp9haOohLgS6dlFLFyxm/wiKw/d2ov2zQMrPFYZs8BR3ORT8i2/Ks1GWm4aOi//epkMaoI0GQmX0ul0rF//TV2HIRqpg0nZvL16Pzqdjocm96J9dMXJAC58+OuDipuMnNsuc7EZLTe10TYXQSNNCEopdDU0UZWoHQ245VLUke92nmXFt8eICvHhgUkxhAdVPltoyVPG+qAodJ5+4O7t3HY5tLw0DK16VTfkeq/RJQS93g2Hw47B4PqFLUTNcTjs5Q6nFaI8m3edZdk3R+nZPoQ/j+2Gt+flfZRpuang6Yveyx8AfVCks6O4MspSiDLlN+oaQqPrQ/D29qOgIBelml6ncUOllEZBQQ7e3o2zXVbUrAMns1n+zTF6tg/hgYkxl50M4PxDZRd9oOuDoi67hnChualxPpQGjbCG4OcXSE5OJunpZ4HymyH0ev0lx/03VvW33Do8PLzw87t0+68QqecKeXv1fqJCffjz2G5VXvRey03FrWVP52t9YCT2Y4komxmd+6XXTb64/6GxanQJQafTERwcfsljmspQvD9qquUWjUOh2cY/P9uLm5uOB6tYMwBQ1qLzTT4XvuE7RxrlpeEW2uaS52t5aaB3Q9cAp7W+XI2uyUgI0fgopXh//SGy8szcd3MPQi+jA/mPLu5QLnFh6GnlzUZabhr6gIhy1kBoPFyaENatW0dsbCwjRoxg2bJlZfYfOHCAiRMnMnbsWO666y7y8/NdGY4QooHa+MsZfjuexa1Dr6Jjy6BqXaO8PoDioae6y3oWoXjIaePtPwAXJoT09HQWLVrE8uXLWb16NStXriwzN86CBQuYO3cua9eupW3btrz//vuuCkcI0UAdP5vHZ1t+p0/HMIb3bVHt65SsY1Dy/AGAzuCBzj+00oSgNAdafnqj7j8AF/YhJCYm0r9/f+fKYCNHjiQhIYH7778wF76maRQWFgLFS0sGBkqnohDigoLcXL5d+zUhga35U2znCp8vsh1LRBXlOV/n+nliNZaeBNJ+Zh+6gLAy6xjog6JwZPyOdc/XFcahrEWgORrttNclXJYQMjIyCAu70PkSHh7O3r17Sx3z2GOPMXv2bF566SW8vb1ZtWpVle5xqTk5KhMW5l/tcxuyplpuaLplb6jlttk1Ej5aym2GzWgT/07rlmVnLgWwZady5vslpbaVnQ+4mH+v4WXej9yrYsj+fi+W7SsvHZDeQGjnGDxC6/f7eSW/b5clBE3TSmXzPz49bDabefLJJ/nvf/9LTEwMH3zwAY8++ihLliwp73LlKm9yu8vRVEfbNNVyQ9Mte0Mtt1KKDxOO4HUuG3zA15ROZmb5o3vsp44B4D3mUdzC2gIQGupHVpax7HUNnmXfjw7D8WsziIqGqTvp3chT7lCP3896O7ldZGQkmZmZzteZmZmEh19ouzt69Cienp7ExMQAMHnyZH755RdXhSOEaEC+2XGWH/ak0LVF8WiiS7Xxl4wQcgtphc7dC527F3oPb+fPpf6roMlJ5+5Z/vEX/+fW+Gc/cFlCGDBgANu2bSM7OxuTycSmTZsYPHiwc3/r1q1JS0vjxIniRVq+++47evTo4apwhBANxJ7jWazcfIw+HcPoEFH8sNilE0IqOu8AdJ4VrwkuLo/LmowiIiKYN28eM2bMwGazMWnSJGJiYpgzZw5z586lR48evPzyy/zlL39BKUVISAgvvfSSq8IRQjQAvyfn8fbq/bSK8OfOMV3RtiYCXHKpSy0vrdGP/qktLn1SOT4+nvj4+FLb3n33XefPQ4YMYciQIa4MQQjRQKRkFfLGp3sI8vdk3i098fRww2QzA5XXEAxtrq6tMBs1eVJZCFHnsvPN/N+q3zC46Xloci8CfD0AUOcTgirMQVnLLjGrzEaUuUBqCDVEEoIQok7Z7A4Wf74Pk8XOvFt7llrXQNnMcL4jWMtLL3NuU5iBtDZJQhBC1KkV3x3nVHoBc8Z0o1XEH8bQW03og6IByl23oKRvQR8oNYSaIAlBCFFnfj6QxpbdyYy+thW9OoSW2a9sZvShrUBX/nxDWm4q6A3o/MueK6pOEoIQok6kZBXyYcIROrYIZMKQduUeo2zm4kXt/cPKnZFUy01FHxjeqGcgrU2SEIQQtc7u0Pj32gN4uOu5a1x33PRlP4qU0uD8wjXFK5uVX0OQ5qKaIwlBCFHrvt5+mjMZRmaN6kwzf8/yD7IVz0ikc/dCHxiJlpdeamlcpdnR8jNlhFENkoQghKhVKVmFrPvpJNd0Dqd3x4pXHysZcsr5GgIOK8qYfWF/fhYohySEGiQJQQhRazSl+O/Xh/F0d2PaTR0vffD5hKDz8LpoZbMLzUYy5LTmSUIQQtSa73clczw5j6nDOxB4/uGzipQ8iKZz9y619nGJkmGojX2NgtokCUEIUStSsgr59PvjdG8XzHXdKv8Qv7jJSOflDx4+ZWoIMqldzZKEIIRwOavNwTtr9uPp4cbs2C4VTkN9MXVRk5FOpysz0kjLlUntapokBCGEy63cfJyzmYXcOaYrQX4VjCr6o5KE4F48BbY+KLJMDUGGnNYsl852KoQQOw5n8P3uZEb1a0WPdiGXfd7FTUZQvPax/ehP2E78ApqGshilhlDDJCEIIVwmv9DKhwmHaRvlX+HTyBVR1pIaQvFkd26hbQAwf/uW8xh9aKuaCVQAkhCEEC706ffHMVsd3BHXFYNbFVuobabimU4NxaOR3KK74Xvryyi7FQCdwRNdYERNh9ykSUIQQrjE0TO5/LQ/jdj+rWkeWvWRQMpmLh5hdL4DWqfToZMmIpeSTmUhRI1zaBofbzpCSIAn8QPaVOsaymp2NheJ2iEJQQhR477bcZazmYVMubEjnh7VnInUZnKOMBK1QxKCEKJG5RktfLn1JDHtQ7i6Y/XXKShpMhK1RxKCEKJGffnjSex2jak3drisB9AqomxmdB6SEGqTJAQhRI05m2Hkx70pDLu6BRHBPld2MatZmoxqmSQEIUSNUEqxcvMxfDwNxA9sc+XXs5lAOpVrlSQEIUSN2HcimwNJOcQPbIuft/sVX0/ZpIZQ2yQhCCGumEPTWPX9ccKbeTPs6uiauaj0IdQ6SQhCiCv2za9nSckq5NahV1X9ieRyKIcNNIeMMqplkhCEEFckK9fE6q0n6HVVKL07VH+Y6cXUH2Y6FbVDEoIQotqUUizddASdTsftIzpe0TDTUqySEOqCJAQhRLX9ciiD/SeymTC4HcEBNffhrWzFy2fiIaOMapMkBCFEtRhNNlZ8e5S2Uf7ceHWLGr22NBnVDUkIQogq0zTFv9ceoMhiZ+aozuj1NdRUVEKajOqESxPCunXriI2NZcSIESxbtqzM/hMnTjB9+nTGjh3LHXfcQV5enivDEULUkC9/PMGBk9ncPqITrSL8a/z6F1ZLkyaj2uSyhJCens6iRYtYvnw5q1evZuXKlRw/fty5XynFPffcw5w5c1i7di1dunRhyZIlrgpHCFFDdhzO4KttpxjSqzmDezZ3yT1K+hDkOYTaVWlCyMnJqdaFExMT6d+/P0FBQfj4+DBy5EgSEhKc+w8cOICPjw+DBw8G4O677+a2226r1r2EELUjLbuI9zccon3zAKYN7+i6G0kfQp2oNCHExcXx17/+lR07dlTpwhkZGYSFhTlfh4eHk56e7nx9+vRpQkNDeeKJJ7j55puZP38+Pj5XOBmWEMKlVv94AoB7b+6Bu8F1Lc4l6ynLg2m1q9IlNDdv3sxXX33FwoULMZlMTJkyhXHjxuHn53fJ8zRNKzUmWSlV6rXdbueXX37h448/pkePHrzxxhu88sorvPLKK5cdfEjIpWO4lLCwmm/3bAiaarmh6Za9psqdkmlkx+EMbr7hKjq2q5kH0Cpyzt2BzeBBeERQta8hv++qqzQheHl5MXHiRCZOnMj27dt54okneO211xg/fjxz586lWbNm5Z4XGRlZqlaRmZlJeHj4RUGH0bp1a3r06AHAmDFjmDt3bpWCP3fOiKapKp1TfG9/MjMLqnxeQ9dUyw1Nt+w1We5lXx9Cr9dzfbcIl7+X5rx8cPeq9n3k910+vV53yS/Sl1Xn++GHH3jggQeYN28ew4cP55NPPiEqKop77723wnMGDBjAtm3byM7OxmQysWnTJmd/AUDv3r3Jzs7m8OHDQHFNpFu3bpcTjhCilmXnm/lpXxqDe0YR6Ofp8vvJaml1o9IawtChQwkKCmLatGn8/e9/x8ur+JfUqVMnVq5cWeF5ERERzJs3jxkzZmCz2Zg0aRIxMTHMmTOHuXPn0qNHD958802eeuopTCYTkZGRLFy4sOZKJoSoMQm/nAZg1LWtauV+ShbHqRM6pdQl21x27dpFp06d8PX1xWq1UlBQQEhISG3Fd0nSZFQ1TbXc0HTLXhPlzi+08sjbiVzTJZw74rrWUGSXVrTuFVAaPmOfqNb58vsu3xU3GaWlpXHzzTcDkJycTFxcHJs3b65GqEKIhmjNTyex2TVi+7eutXsWr5YmNYTaVmlCeOedd1i6dCkAbdu25csvv2Tx4sUuD0wIUfcOJmXz/a5kbuzbgqgQ31q7r7KZ0cnEdrWu0oSgaRqRkZHO11FRUWia5tKghBB1r8hs54MNh4gI9mHSkPa1e3PpQ6gTlSaE4OBgPvnkE+x2Ow6Hg88++4zQUNeOQRZC1L1PNh8ju8DCnXFd8HB3q9V7yyijulFpQnj++edZtWoVMTExxMTEsGrVKubPn18bsQkh6sje37PYujeV2P6taR8dWKv3VkoDu0VqCHWg0mGnbdq04YsvviAvLw83N7dKn1AWQjRsdofG8m+OERXiw9iBbWs/AJsFkInt6kKlCSE7O5u1a9dSWFiIUgpN0zh16hSvv/56bcQnhKhlm3clk5FrYt6tPV06X1FFlPX8amky9XWtqzQh/OUvf8HLy4vjx48zYMAAEhMT6dOnT23EJoSoZUaTjXU/naRbm2Z0bxtcJzHIaml1p9L0n5KSwpIlSxg8eDC33347K1as4MSJE7URmxCilq1PTKLIbOfWYR1KTUZZq0oSgjQZ1bpKE0LJiKI2bdpw9OhRIiIisNvtLg9MCFG7MnKK+G7nWa6PiaJleN31FcpqaXWn0iajkJAQ3nvvPXr16sXixYvx8/PDbDbXRmxCiFr06ZbfcXPTMX5QuzqNw7lamjQZ1brLGnbq4eFB37596d69O//85z/529/+VhuxCSFqyaFTOew8kkls/9Y083f9bKaXZJU+hLpSaQ3h1Vdfdc5C+vDDD/Pwww+7PCghRO1xaBrLvz1KaKAXo/rVzmyml1JSQ5AH02pfpQnh0KFDZVY7E0LUf0pzoNmtKLv1ksf9b3cy6Zn53DW2K+46B8ruqKUIy6csRQAyl1EdqDQhhIeHExcXR8+ePfH1vTC51VNPPeXSwIQQ1acshRg/eQSjpbDSY68BrgkGtoJxq8tDuzx6A7i513UUTU6lCaF379707t27NmIRQtQQR/ZZsBTi3/smLO4VTz2x+2gWJ1PyGd63BQF+HrUY4aXpg6KkVaIOVJoQ7r///tqIQwhRg7TcVACCBk4g11p+08uxs7m8m7CLG/u0IOz6jrUZnqinKk0I8fHx5W5ft25djQcjhKgZWm4quHlgCAiFrLLNRja7gw82HCY4wIsJQ+p2mKmoPypNCE8//bTzZ5vNxldffUXLli1dGpQQ4spouanogyLQ6cofWb72pyTSsot4aHJPvDwq/RgQTUSlfwn9+vUr9XrAgAFMmTKFe+65x2VBCSGujJaXhltom3L3nUor4OufTzOwRyTd29aP9dFF/VDlqQxzcnLIyMhwRSxCiBqgHDZUQSb6oKgy++wOjQ82HMLfx50pN3aog+hEfVblPoSUlBQmT57ssoCEEFdGy8sApdAHRZbZtz4xidMZRu6f0ANfLxnWKUqrUh+CTqcjODiY9u1reX1VIcRl03JTAMrUEE6lFfDVtlNc1y2CqzuG1UVoop6rtMmoVatWbNiwgX79+hESEsLrr79OVlZWbcQmhKgGLS8NAH3ghRqCza7x3vqD+Pu4M+0mGWIqyldpQnjsscdo1654WFp0dDT9+vXj8ccfd3lgQojq0XLT0PkGl5ocbs3WkyRnFTJrdBdpKhIVqjQh5OTkMGPGDAA8PT2ZNWsWmZmZLg9MCFE9xUNOL9QOktLy+Xr7KQbFRBHTXkYViYpVmhAcDgfp6enO11lZWSilXBqUEKJ6lFJoeanoA4v7D+wOjf9uOEyArweTh8moInFplXYqz5o1i/HjxzNo0CB0Oh2JiYk88sgjtRGbEKKKlCkPrCZnDWHN/37ndIaR+27ujo+XPIAmLq3Sv5BJkybRvXt3fv75Z9zc3Ljzzjvp0EG+aQhRH2m55zuUg6JIzyli+cbDXN0xjD6dwus4MtEQVNpklJ6ezieffMKsWbMYOHAgixYtkj4EIeqpkkntdIGRLE04gsGg5zYZVSQuU6UJ4dFHHy0zyuiJJ55weWBCiKrT8tLA4MHOMzYOncphZlzXul8SUzQYLh1ltG7dOmJjYxkxYgTLli2r8LgtW7YwbNiwywxZCFERLTcVXUAEn245SctwP0b2b1PXIYkGxGWjjNLT01m0aBHLly9n9erVrFy5kuPHj5c5Lisri1dffbWKYQshyqPlppLmCORcvpmpN3bATS+LzIjLV2lCKBll9Mgjj/DII49w8803c+edd1Z64cTERPr3709QUBA+Pj6MHDmShISEMsc99dRTsgiPEDVA2a1oBVnszTDQp2MYnVs3q+uQRANT5VFGrVq1YunSpRUunFMiIyODsLAL86WEh4ezd+/eUscsXbqUrl270rNnz2qGL0TTYDvxK/bjP+M94oEKj9HyM9ChSHf4c8tQmW9MVN1lDUyOiorCarWybNkyioqKmD59eqXnaJpWak1UpVSp10ePHmXTpk3897//JS0trRqhQ0iIX7XOAwgL86/2uQ1ZUy03NOyyp/+0B3PSToJ9wc2n/HIcPHAaL6BLz+506xjh3N6Qy30lpNxVd8mEcOLECT788EPWrl1LdHQ0ZrOZzZs34+9f+Q0jIyPZsWOH83VmZibh4RfGQickJJCZmcnEiROx2WxkZGQwbdo0li9fftnBnztnRNOq/tR0WJg/mZkFVT6voWuq5YaGX3ZT+hkAMn8/hltk2eeA8owWtv5vJ8MN0O+a7s6yNvRyV5eUu3x6ve6SX6Qr7EP485//zO233467uztLly5l/fr1+Pr6XlYygOKV1bZt20Z2djYmk4lNmzYxePBg5/65c+eyceNG1qxZw5IlSwgPD69SMhCiqVBKOR84K3nO4GIOTeOdNQdopuWgeTfDx8+3tkMUjUSFCeHgwYN069aNDh060Lp1a4BSTT6ViYiIYN68ecyYMYPx48czZswYYmJimDNnDvv27bvyyIVoIlRhDtgtwIWprS/2xQ8nOHImly7BVtyDm9d2eKIRqbDJaMuWLWzatIkVK1awYMECbrjhBiwWS5UuHh8fX6bz+d133y1zXIsWLdi8eXOVri1EU3FxreCPNYR9J87x9c+nuaFnFD5pWeiDOtV2eKIRqbCGYDAYiI2N5aOPPuKLL74gPDwci8XCiBEjWLFiRW3GKESTpuUVJwF9ePtSCaHIbOODDYeIDvVlysBwsJmds5wKUR2VPocAcNVVV/HUU0/xww8/cMcdd7Bq1SpXxyWEOE/LTQV3LwzNu6DlZ6I0OwArvjtGfqGN2XFd0BszgLLLZgpRFZeVEEp4e3szefJkvvzyS1fFI4T4Ay03DX1QVPGHvXKg8jPZczyLn/alMbp/K9pGBThrDhcvjCNEVckE6ULUc1puKm5RnZwf9kUZZ/lwk4XoMF/GDmzrPAaDJzpfeTpZVF+VaghCiNqlbBZUYXZxDSGwOCHs2X2guKkotgvuhuJ/wlpeGvrASHQ6+Sctqk/+eoSox0qGmeqDItF5+uLw8Kco4yyjri1uKnIed75ZSYgrIQlBiHrsQt9AFBargzMWP6I9Cxg7sI3zGGW3ogqypP9AXDFJCELUY8U1BB36gAi+/PEEyRY/mrsb8XB3u3BMfjqgpIYgrpgkBCHqMS03FZ1/CL+nm/jm1zMERLXCzVaIZi4odQzg7GMQorokIQhRj2m5adh9w/nXF/sIDvCi59XdnNsvPgZkyKm4cpIQhKinlNJw5KayM1WPw6Ex79aeeIe1AEDLTXEep+WmovMLQWeQtZPFlZHnEISop0w5WegcVs6Y/fjLLT1pHuqL0rxBbyhdQ8iTEUaiZkgNQYh6yKFprNuwDYABA3rRPjoQAJ1ejz4wwtlvUDw1dqr0H4gaIQlBiHrok2+PU5SZDMBV3TqX2qcPinI+n6CKcosntZMagqgB0mQkhIsomwXz5ndQ1qIqnZdTYKFrjonoQBPovNB5B5barw+MxJ60k6J1L6Os5uJtkhBEDZCEIISLaDlnsZ/ajT64JTrPy1vFrNBsIz3HjK+3O75hzTA071JmYSpDu2twZJ4EzYHOwxtDm6txC2/niiKIJkYSghAuosxGALwGz8ItvH2lxydnFfLSRzsJDvDkidv64O1Z/j9Pt9DW+MQ9XKOxCgHShyCEy5QkBJ1X5euQ5xVa+cene3A36HlwUkyFyUAIV5KEIISLqPNPE+u8/C55nNXmYPHne8kvtPLgpBhCA71rIzwhypCEIISLKLMRdG7gXvEHvKYp3lt/kJMp+cyJ71pqBlMhapskBCFcRJmN6Lx8y3QKl9CU4j8bDrHjSCaTh11Fn07htRyhEKVJQhDCRZS5oML+A6UUSxOOkLg/jZsHtWVEv1a1HJ0QZUnPlRAuoizGcvsPNKVY8c0xftiTQtx1rYk/vwymEHVNEoIQLqLMBegDSz8wZndo/GfDIX4+kM7Ifi2ZMFieHxD1hyQEIVxEmY3oIi40GZksdt78ch8Hk3KYOKQdsf1bV9i/IERdkIQghAsopc53Khc3GRWZbfx9xW+cyTAyO7YL18fIVBOi/pGEIIQrWItAaei8/LHaHPzjs72czTTywMQe9LwqtK6jE6JcMspICBdQlsLi/3v68M6aAxw/m8ec+K6SDES9JjUEIVyg5Cnl7w/k8dtxG9OGd6Bfl4g6jkqIS5MaghAuYDXmAfDz70WMGdCa4X1b1nFEQlROEoIQNSzXaOGrLQcAGHJtB24eJENLRcPg0oSwbt06YmNjGTFiBMuWLSuz/9tvv2XcuHGMHTuWe++9l7y8PFeGI4TLHU/O44UPd2A15gNwQ/9OMrRUNBguSwjp6eksWrSI5cuXs3r1alauXMnx48ed+41GI88++yxLlixh7dq1dOrUicWLF7sqHCFcSlOKr7Yl8crHu3DT6xjeI6jSie2EqG9clhASExPp378/QUFB+Pj4MHLkSBISEpz7bTYb8+fPJyKiuKOtU6dOpKamuiocIVwmv9DKopW/8fn/TnB1pzCe/VM/Atys6Lz8pHYgGhSXjTLKyMggLCzM+To8PJy9e/c6Xzdr1oybbroJALPZzJIlS5g+fbqrwhHCJZLS8ln8+T6MJhszR3VicM/m6HQ6TOby5zESoj5zWULQNK3UtyOlVLnflgoKCrjvvvvo3LkzN998c5XuERJS/X9wYWGVr2LVGDXVckPNl/37nWf416rfCPT3ZOEDg7iqRZBzX4pmAv+gevF+14cY6oKUu+pclhAiIyPZsWOH83VmZibh4aXne8/IyOCOO+6gf//+PPHEE1W+x7lzRjRNVfm8sDB/MjMLqnxeQ9dUyw01W3alFGu2nmTtT0l0bhXE3eO7E+DpVur61oJc9EHN6/z9bqq/cyl3+fR63SW/SLusD2HAgAFs27aN7OxsTCYTmzZtYvDgwc79DoeDu+++m9GjR/Pkk09KW6toEJRSfLbld9b+lMT1MVE8NLkXAT4eZY+TJiPRALmshhAREcG8efOYMWMGNpuNSZMmERMTw5w5c5g7dy5paWkcPHgQh8PBxo0bAejevTsLFixwVUhCXBGlFCu+O8a3O84y9OpobrupI/pyvsg4J7bzlIQgGhaXTl0RHx9PfHx8qW3vvvsuAD169ODw4cOuvL0QNcJmd7DraBZbdidz5EwuI65pyeRhV1Vcq71oYjshGhKZy0iICtgdGhu2neKbHWcoNNsJCfBi6o0dGN63xSWbOJXZCCBNRqLBkYQgRDlSsgp5d/1BTqUV0LtDKMOubkGXNs3KbSL6o5KJ7SQhiIZGEoIQF7HZNb7deYbVP57E092Ne8d3p2/n8MpPvIiylNQQpMlINCySEISgeOqJXw6l88X/TpCVZ6bXVaHMHNWJQD/PKl9LmoxEQyUJQTRpmqbYdTST9duSOJ1upGW4Hw9N7kn3tiHVvuaFJiOpIYiGRRKCaJLsDo3E/Wl8/fMp0nNMRDTz5s4xXejfLfKy+gkuRZmN5ye286qhaIWoHZIQRJNid2hs3ZvKV9tOcS7fTOsIf+4d352rO4ah19fMw5ElD6XJw5aioZGEIJoEi83BdzvP8vX2U2TnW2jXPIDpIzvRo11wjX9wFycEaS4SDY8kBNFo2R0aZzKM7D+Zzfe7ksk1WrgqOpBZozrTrW3NJ4ISylwgHcqiQZKEIBo8s9XOr4cyOHQqB4vNgc2uYTTZOJtpxO4onvzw6k7h3NQnmo4tg1zelKMsRvRBzV16DyFcQRKCaDA0TfHb8SxOpRVgcNNhMOhJO1fEL4czsFgdNPP3xNfLHXeDHm9PA8P7tKRt8wDaRQXQ+aqwWpv9Uia2Ew2VJARR79nsGtsOpPH19tOkZxeV2ufhrqdflwgGxzSnfXRAnXfkKqVJH4JosCQhiHonv8hKalYhx5PzOHw6l2Nnc7HaNFpH+HP3uG707RSOphR2h4abXo+7wWWzuFed1VQ8sZ3MdCoaIEkIok4ZTTZ+T87jeHIex8/mkZxViNFkc+6PDvVlUI/m9O4YSpfWzZw1AD06DG71KBGcJ08pi4ZMEkIjppnysR/ditI0AHJ8PbEUWuosHqUUOQUWMnKKyDFayTNaKDTbAdDrdPT082BwpCf+Pu4E+HgQ6OeJl0cRkAk5R7HmVP/etVV2VVgcpDQZiYZIEkIjZjv0PdYdXzpfW+swlhJ+5/8Ditfr87lopwPIO//feTUVc62W3c0DfVBkbd5RiBohCaER03JS0fmF4Dv5FQDCQv3JzKr5kTZFZjtJ6QWcTM4jKa2ApLQC8govfATrgCB/Tzq1DKJ7u2C6tgnGz9u9xuO4FFeVvVw6PTq9W+3cS4gaJAmhEdPyUtEHRaFzK/7w1RncnT9fqVyjhV8PZfDLoXROpOSjzm+PCvGhU5sw2kb50yrCn9BALwJ8Peq8vb8myy5EYyUJoZFSSqHlpuHeuWONXK/IbON4ch5HzuRy9HSuMwm0Cvdj3PVtad8ikLaRAfh4yZ+UEA2V/OttpFRhDtgt6IOiqnV+rtHCr4czOH42j1NpBWTkmgBw0+toGxVA/MA29OsSQfNQ35oMWwhRhyQhNFJaXhpAlRLCuTwz+0+e45dDGRw+lYMCQgK8aBPpz/UxUbRvHkC76EA83aV9XIjGSBJCI6XlpgCgD6x4tEuh2caR07kcSsrhQFI2aeefAg5v5k38wDZc2zWCqBCpAQjRVEhCaKS03DRw90LnE1Rqe3a+me2H0tlxOIOktAKUKp7+oVPLZtzQqzld2wYTHepb51NACCFqnySERkrLTUUfGElOgYVTaQWcSi/gZJqR/b9noaC4H2BAG7q2CaZd84A6HwUkhKh7khAamfxCK4dO5dA67Qy/28J5/61EAHQ6aBXhz7jr23JttwgimvlUciUhRFMjCaEBKpkCIrvAgtFkw1hUPPf/waQczmYa8cDG34Pzcfj1YFrfDrSNCqBFuB8tmgfV2hTQQoiGRxJCA+DQNI6eyWPX0UySUvNJOVeIyeIodYzBTUeHFkFMHNKO7kFF8CNcN6AX7u1a1lHUQoiGRhJCPZRntHAm00hyZiGn043sO3EOo8mGh0FP26gA+neLJDrUl9BAb/y83fHzcaeZnwfuhuLhoLbjP2MGmU9HCFElkhDqmEPTSEot4NCpHE6m5nMyNZ9c44V5gAJ83Onaphl9O4XTo10Inh6VPwNQ/AyCDn1AhAsjF0I0NpIQaonJYudgUg4nUvKw2jSsdgcFRTaOnMnFZCmeAjoy2IfOrZvRJjKAVuF+NA/zJcDHo8r30nJT0fmHojNU/VwhRNMlCaGGmSx2kjMLSc8pIr/ISp7RSnJWIUdO52B3KAxuOjzd3Zzr/l7TOYyubYLp0roZ/tX48C+PlptW7SkrhBBNlySEK6RpisOnc9i2P40jZ3LJyjOX2u/hrics0JvhfVrS86oQ2kcHunTMv1IaWl4q7lGdXHYPIUTj5NKEsG7dOt5++23sdjszZ87ktttuK7X/0KFDPPnkkxQWFtK3b1+ee+45DIb6maPsDo2UrEJOpReQa7RSZLZRaLJzICmbnAIL3p4GurcNZkiv5rQI8yMy2IdAPw+8PGq3PMWT2lmlhiCEqDKXfVqlp6ezaNEivvjiCzw8PJgyZQrXXnstV111lfOYhx9+mBdffJFevXrxxBNPsGrVKqZNm+aqkCqklEIpsDk0co0WsvMtZOebycgxkZFrIi27iOTMQuwOzXmOh0GPt5eB1hH+TB52Fb2uCsWjHkz6puWmAjLCSAhRdS5LCImJifTv35+goCAARo4cSUJCAvfffz8AycnJmM1mevXqBcCECRP45z//6fKEcDo1h5VLP6Wo0ILF5sBqd+Bc3eWPdODv7UEPPw9u6ORFWJAXYUE++Hu74+ZWMtePBTgFZ05hq+Aytclx9iBQtVlOhRACXJgQMjIyCAsLc74ODw9n7969Fe4PCwsjPT29SvcICfGr/KA/KPp9B7Hmr8CN4v8uh+n8f8UzSmM7/1995ebXjPBWLcqdoC4srOku/t5Uyy7lblqupNwuSwiappX6QFJKlXpd2f7Lce6cEU2r6Ot9+Xza9yWo42LOZeZX6byGRO8TSFaWscz2sDD/Jjt1RVMtu5S7aams3Hq97pJfpF2WECIjI9mxY4fzdWZmJuHh4aX2Z2ZmOl9nZWWV2u9K7sHNcXM0zW8PQghREZeNfxwwYADbtm0jOzsbk8nEpk2bGDx4sHN/dHQ0np6e7Ny5E4A1a9aU2i+EEKJ2uSwhREREMG/ePGbMmMH48eMZM2YMMTExzJkzh3379gHw2muv8fLLLzNq1CiKioqYMWOGq8IRQghRCZ1SqmqN8PVIdfoQQNoXm6KmWnYpd9NypX0IskyWEEIIQBKCEEKI8yQhCCGEABr45HZ6fdWeW6ipcxuyplpuaLpll3I3LZcqd2XvSYPuVBZCCFFzpMlICCEEIAlBCCHEeZIQhBBCAJIQhBBCnCcJQQghBCAJQQghxHmSEIQQQgCSEIQQQpwnCUEIIQTQBBPCunXriI2NZcSIESxbtqyuw3Gpf/3rX8TFxREXF8fChQsBSExMJD4+nhEjRrBo0aI6jtC1Xn31VR577DGgaZR78+bNTJgwgdGjR/Piiy8CTaPca9ascf6dv/rqq0DjLrfRaGTMmDGcPXsWqLishw4dYsKECYwcOZInn3wSu91e+cVVE5KWlqaGDh2qcnJyVGFhoYqPj1fHjh2r67Bc4qefflKTJ09WFotFWa1WNWPGDLVu3To1ZMgQdfr0aWWz2dTs2bPVli1b6jpUl0hMTFTXXnutevTRR5XJZGr05T59+rS6/vrrVWpqqrJarWrq1Klqy5Ytjb7cRUVF6pprrlHnzp1TNptNTZo0SX333XeNtty//fabGjNmjOrWrZs6c+bMJf+24+Li1O7du5VSSj3++ONq2bJllV6/SdUQEhMT6d+/P0FBQfj4+DBy5EgSEhLqOiyXCAsL47HHHsPDwwN3d3fat29PUlISrVu3pmXLlhgMBuLj4xtl+XNzc1m0aBF33303AHv37m305f7mm2+IjY0lMjISd3d3Fi1ahLe3d6Mvt8PhQNM0TCYTdrsdu92On59foy33qlWrmD9/vnP9+Yr+tpOTkzGbzfTq1QuACRMmXNZ70KBnO62qjIwMwsLCnK/Dw8PZu3dvHUbkOh06dHD+nJSUxNdff83tt99epvzp6el1EZ5LPfPMM8ybN4/U1FSg/N97Yyv3qVOncHd35+677yY1NZUbbriBDh06NPpy+/n58eCDDzJ69Gi8vb255pprGvXve8GCBaVeV1TWP24PCwu7rPegSdUQNE1Dp7sw/atSqtTrxujYsWPMnj2bRx55hJYtWzb68n/66adERUVx3XXXObc1hd+7w+Fg27ZtvPTSS6xcuZK9e/dy5syZRl/uw4cP8/nnn/P999/z448/otfrSUpKavTlLlHR33Z1/+abVA0hMjKSHTt2OF9nZmY6q16N0c6dO5k7dy5PPPEEcXFx/PLLL2RmZjr3N8byb9iwgczMTMaNG0deXh5FRUUkJyfj5ubmPKYxljs0NJTrrruO4OBgAIYPH05CQkKjL/fWrVu57rrrCAkJAYqbRt5///1GX+4SkZGR5f6b/uP2rKysy3oPmlQNYcCAAWzbto3s7GxMJhObNm1i8ODBdR2WS6SmpnLffffx2muvERcXB0DPnj05efIkp06dwuFwsH79+kZX/g8++ID169ezZs0a5s6dy7Bhw3jvvfcafbmHDh3K1q1byc/Px+Fw8OOPPzJq1KhGX+7OnTuTmJhIUVERSik2b97cJP7OS1RU1ujoaDw9Pdm5cydQPBLrct6DJlVDiIiIYN68ecyYMQObzcakSZOIiYmp67Bc4v3338disfDKK684t02ZMoVXXnmFBx54AIvFwpAhQxg1alQdRlk7PD09G325e/bsyZ133sm0adOw2WwMHDiQqVOn0q5du0Zd7uuvv56DBw8yYcIE3N3d6dGjBw888AADBw5s1OUucam/7ddee42nnnoKo9FIt27dmDFjRqXXkxXThBBCAE2syUgIIUTFJCEIIYQAJCEIIYQ4TxKCEEIIQBKCEEKI85rUsFMhLlenTp3o2LEjen3p70xvvvkmLVq0qPF7bdu2zflQmRB1RRKCEBX48MMP5UNaNCmSEISoou3bt/Paa6/RvHlzTpw4gZeXF6+88grt27enoKCA5557jsOHD6PT6Rg0aBAPPfQQBoOBPXv28OKLL2IymXB3d+eRRx5xzrm0ePFi9uzZQ25uLnfccQe33XZbHZdSNEWSEISowMyZM0s1GbVo0YI333wTgP379/Poo4/St29fVqxYwcMPP8wXX3zBiy++SFBQEOvWrcNms3HPPffwn//8hz/96U/cd999vPjii9xwww3s37+fxx9/nDVr1gDQsmVL5s+fz8GDB5k8eTK33nor7u7udVJu0XRJQhCiApdqMurcuTN9+/YFYOLEiTz//PPk5OTwww8/sGLFCnQ6HR4eHkyZMoUPP/yQgQMHotfrueGGGwDo3r0769atc15vzJgxAHTp0gWr1YrRaKRZs2auLaAQfyCjjISohotn07x42x+nHdY0DbvdjpubW5nph48ePepc1tBgKP5uVnKMzCgj6oIkBCGq4fDhwxw+fBiAlStX0rt3bwICArj++uv5+OOPUUphtVpZtWoVAwYMoF27duh0On766ScADhw4wMyZM9E0rS6LIUQp0mQkRAX+2IcA8NBDD+Hl5UVoaChvvPEGycnJBAcHs3DhQgCeeuopXnzxReLj47HZbAwaNIi7774bDw8PFi9ezEsvvcTChQtxd3dn8eLFeHh41EXRhCiXzHYqRBVt376dF154gfXr19d1KELUKGkyEkIIAUgNQQghxHlSQxBCCAFIQhBCCHGeJAQhhBCAJAQhhBDnSUIQQggBSEIQQghx3v8DtveQeXqXPuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Model Accuracy ')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train accuracy', 'Valid accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fd251336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.set_theme()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model loss ')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train loss', 'Valid loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0a82c",
   "metadata": {},
   "source": [
    "# Save model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "02d4f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/Users/ghadeeraboalrob/ghadeer/transformer_model/txt_generation_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc04f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "715e4bb1",
   "metadata": {},
   "source": [
    "# Testing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b306b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_seq =  test_dataset['id_word_x'].tolist()\n",
    "test_input_seq = np.array(test_input_seq, dtype=np.int32)\n",
    "\n",
    "y_test = np.array(test_dataset['one_hot_y'].tolist(), dtype=np.int32)\n",
    "\n",
    "test_input_topic = test_dataset['id_word_topic'].tolist()\n",
    "test_input_topic = np.array(test_input_topic, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f8cae1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 179ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_=model.predict([test_input_seq, test_input_topic],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f5c2c",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0d52bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.0%\n",
      "\n",
      "Macro metrics:\n",
      "Precision: 92.81\n",
      "Recall: 92.81%\n",
      "F score: 92.81%\n",
      "\n",
      "Micro metrics:\n",
      "Precision: 95.0\n",
      "Recall: 95.0%\n",
      "F score: 95.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghadeeraboalrob/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ghadeeraboalrob/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "true=[np.argmax(y_[i][-1]) for i in range(len(y_))]\n",
    "pred=[np.argmax(y_test[i][-1]) for i in range(len(y_))]\n",
    "total=0\n",
    "print(f'Accuracy: {round(100*(sum([(true[i]==pred[i]) for i in range(len(pred))])/len(pred)),2)}%\\n')\n",
    "\n",
    "prf = precision_recall_fscore_support(true, pred, average='macro')\n",
    "print('Macro metrics:')\n",
    "print(f'Precision: {round(prf[0]*100,2)}\\nRecall: {round(prf[0]*100,2)}%\\nF score: {round(prf[0]*100,2)}%\\n')\n",
    "prf = precision_recall_fscore_support(true, pred, average='micro')\n",
    "print('Micro metrics:')\n",
    "print(f'Precision: {round(prf[0]*100,2)}\\nRecall: {round(prf[0]*100,2)}%\\nF score: {round(prf[0]*100,2)}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f316ab",
   "metadata": {},
   "source": [
    "# Evaluation using semantic approach (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3dd119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dac0709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, embed_dim=256, tokens=None):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding_generator(tokens)\n",
    "        \n",
    "        \n",
    "    def embedding_generator(self, tokens):\n",
    "        self.w2v_model = Word2Vec(tokens,\n",
    "                     min_count=1, # min frequency of a word, ignore words with frequency lower than min_count\n",
    "                     window=10, # maximum distance between the current and predicted word within a sentence\n",
    "                     vector_size=256, # Dimensionality of the result vector\n",
    "                     alpha=0.03, # learning rate\n",
    "                     min_alpha=0.0006, # learning rate will drop during training linearly by min_alpha \n",
    "                     workers = 4, # worker threads to train the model\n",
    "                     seed = 42 # random number generator\n",
    "                    )\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_seq_embeddings(self, seq):\n",
    "        embed=np.array([0]*self.embed_dim)\n",
    "        for i in seq:\n",
    "            embed=embed+ self.w2v_model.wv[i]\n",
    "        return embed\n",
    "        \n",
    "    def cal_similarity(self, txt1, txt2, n_grams):\n",
    "        \n",
    "        seq1=txt1.split(' ')\n",
    "        seq2=txt2.split(' ')\n",
    "        \n",
    "        embed1=self.get_seq_embeddings(seq1[-1*n_grams:])\n",
    "        embed2=self.get_seq_embeddings(seq2[-1*n_grams:])\n",
    "        \n",
    "        return 1-spatial.distance.cosine(embed1, embed2)\n",
    "    \n",
    "    \n",
    "    def evaluate(self, df, n_grams):\n",
    "        return df.apply(lambda x: self.cal_similarity(x['y'], x['_y'], n_grams,), axis=1).mean()\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f3b6adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=topics['text'].apply(lambda x: tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9e1f7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_obj = Evaluation(256, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "db24cd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c191f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[id2vocab[np.argmax(y_[i][-1])] for i in range(len(y_))]\n",
    "true=[id2vocab[np.argmax(y_test[i][-1])] for i in range(len(y_))]\n",
    "\n",
    "test_txt=[]\n",
    "for i in test_input_seq:\n",
    "    test_txt.append([id2vocab[idx] for idx in i ])\n",
    "    \n",
    "true_data=[]\n",
    "pred_data=[]\n",
    "for i in range(len(test_txt)):\n",
    "    pred_data.append(' '.join([t for t in test_txt[i]])+' '+pred[i])\n",
    "    true_data.append(' '.join([t for t in test_txt[i]])+' '+true[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "704a794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity over 4 grams: 99.57%\n",
      "Similarity over 3 grams: 99.38%\n",
      "Similarity over 1 gram: 95.76%\n"
     ]
    }
   ],
   "source": [
    "d=pd.DataFrame({'y':true_data[:100], '_y':pred_data[:100]})\n",
    "print(f'Similarity over 4 grams: {round(evaluation_obj.evaluate(d, 4)*100, 2)}%')\n",
    "print(f'Similarity over 3 grams: {round(evaluation_obj.evaluate(d, 3)*100, 2)}%')\n",
    "print(f'Similarity over 1 gram: {round(evaluation_obj.evaluate(d, 1)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2df0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb5aaa87",
   "metadata": {},
   "source": [
    "# combine LDA with text generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dc2d5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic16 = topics['Topic_Keywords'].unique()\n",
    "TOPICS={}\n",
    "for t in range(len(topic16)):\n",
    "    TOPICS[t] = topic16[t].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41471e2",
   "metadata": {},
   "source": [
    "## Load LDA model with dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7960bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "texts = [[]]\n",
    "dictionary = Dictionary(texts)\n",
    "loaded_dict=dictionary.load(r'/Users/ghadeeraboalrob/ghadeer/models/dict.h5')\n",
    "lda_model =  models.LdaModel.load(f'/Users/ghadeeraboalrob/ghadeer/models/lda_topic_modeling_16_fv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7eaa30",
   "metadata": {},
   "source": [
    "## Get topic using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9455319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"been caused by water hammer pressure because effect example sentence spans and target label for each task ontonotes winograd to cast all tasks into common classication model we focus on the labeling versions of each task spans gold mentions constituents predicates etc are given as inputs and the model is trained to predict as multilabel target we note that this is only one component of the common pipelined or endtoend approach to these tasks and that in general our metrics are not comparable to models that jointly perform span identication and labeling however since our focus is on analysis rather than application the labeling version is better for our goals of isolating individual phenomena of interest and giving uniform metric binary score across our probing suite asks our experiments focus on eight core nlp labeling tasks partofspeech constituents dependencies named entities semantic roles\"\n",
    "new_doc = text.split(\" \")\n",
    "new_doc_bow = loaded_dict.doc2bow(new_doc)\n",
    "top_topics = lda_model.get_document_topics(new_doc_bow)\n",
    "\n",
    "\n",
    "max_topic = top_topics[np.argmax(np.array(top_topics).T[1])][0]\n",
    "print(f\"the relevant topic is {max_topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbbc29",
   "metadata": {},
   "source": [
    "## prepare sequence for text and topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = new_doc\n",
    "seq=seq[-10:]\n",
    "# convert words to ids based on our dictionary\n",
    "seq = list2ids(seq)\n",
    "\n",
    "# get topic keywords\n",
    "topic_seq = TOPICS[max_topic]\n",
    "# convert words to ids based on our dictionary\n",
    "topic_seq = list2ids(topic_seq)\n",
    "\n",
    "# convert sequences into numpy arrays\n",
    "seq=np.array(seq, dtype=np.int32)\n",
    "topic_seq=np.array(topic_seq, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30116",
   "metadata": {},
   "source": [
    "## Predict next ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc41092",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_w=model.predict([seq, topic_seq],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f62a3a",
   "metadata": {},
   "source": [
    "## Decode results ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15675f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_pred=[id2vocab[np.argmax(next_w[i][-1])] for i in range(len(next_w))]\n",
    "\n",
    "\n",
    "new_txt=[]\n",
    "for i in seq:\n",
    "    new_txt.append([id2vocab[idx] for idx in i ])\n",
    "    \n",
    "data=[]\n",
    "for i in range(len(new_txt)):\n",
    "    data.append(' '.join([t for t in new_txt[i]])+' '+next_pred[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df2ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5877580",
   "metadata": {},
   "source": [
    "# End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
